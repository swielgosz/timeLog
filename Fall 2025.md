# December 11
To do before tomorrow:
- metric to record when acceleration is not collinear with position



| label    | wandb_source_id | output_layer         | complex_TBP_planar_1_test (mean) | complex_TBP_planar_1_test (theta-deg) | complex_TBP_planar_1_test (radial%) | complex_TBP_planar_1_test (skewness) | complex_TBP_planar_1_test (pearson-sk1) | complex_TBP_planar_1_test (pearson-sk2) | complex_TBP_planar_1_test (bowley) | complex_TBP_planar_10_test (mean) | complex_TBP_planar_10_test (theta-deg) | complex_TBP_planar_10_test (radial%) | complex_TBP_planar_10_test (skewness) | complex_TBP_planar_10_test (pearson-sk1) | complex_TBP_planar_10_test (pearson-sk2) | complex_TBP_planar_10_test (bowley) | complex_TBP_planar_100_test (mean) | complex_TBP_planar_100_test (theta-deg) | complex_TBP_planar_100_test (radial%) | complex_TBP_planar_100_test (skewness) | complex_TBP_planar_100_test (pearson-sk1) | complex_TBP_planar_100_test (pearson-sk2) | complex_TBP_planar_100_test (bowley) |
| :------- | :-------------- | :------------------- | -------------------------------: | ------------------------------------: | ----------------------------------: | -----------------------------------: | --------------------------------------: | --------------------------------------: | ---------------------------------: | --------------------------------: | -------------------------------------: | -----------------------------------: | ------------------------------------: | ---------------------------------------: | ---------------------------------------: | ----------------------------------: | ---------------------------------: | --------------------------------------: | ------------------------------------: | -------------------------------------: | ----------------------------------------: | ----------------------------------------: | -----------------------------------: |
| 3kj0mdmu | 3kj0mdmu        | mlp_4D_unit_softplus |                              4.3 |                                 0.455 |                                   0 |                                  1.4 |                                   0.634 |                                     1.2 |                              0.364 |                              7.74 |                                  0.659 |                                    0 |                                  3.24 |                                    0.532 |                                     1.12 |                               0.441 |                               6.47 |                                   0.685 |                                     0 |                                    3.5 |                                     0.635 |                                      1.07 |                                0.421 |
Yesterday, I ran a sweep which was more limited with the following config:
```python
wandb:
  group: "sweep-2BP-12-10"  # Change this to your desired group name

data:
  dataset_name : ["complex_TBP_planar_1_train", "complex_TBP_planar_10_train", "complex_TBP_planar_100_train"]
  problem: '2BP'

parameters:



  # EXHAUSTIVE LENGTH STRATEGY
  length_strategy:    [[
                        [0.0, 0.1],
                        [0.0,1.0],[0.0,1.0],],
                        [0.0,1.0],
                      ]

  lr_strategy: [[0.001,0.001, 0.0001]]
  steps_strategy: [[1000,1000,1000]]
  segment_length_strategy: [[4,],[10,],[18,]]


  width: [64]
  depth: [2,4]
  train_val_split: 1
  batch_size: [256]
  num_trajs: -1
  loss_fcn: "percent_error_plus_nmse"
  activation: [tanh, leaky_relu]


  feature_layer: [sph_4D_rinv_vel, sph_4D_rinv_vel_harmonics]
  output_layer: [mlp_4D_signed, mlp_4D_unit, mlp_4D_unit_softplus, mlp_4D_logmag_unit_exp]
  planar_constraint: true

  rtol: 0.000001
  atol: 0.00000001
```
The goal of this was primarily to test the feature layer and the output layer, and secondarily to test the length strat, segment lenght, and activation.

I have the results. What specific parts would I like to analyze?
- Is there a way I can stats and how they relate to layer, output layer, segment_length, and training dataset?
Prompt: Do you remember all those stats we calculated? I would like to show how they relate to a few training parameters. Specifically, I want to analyze the group "sweep-2BP-12-10" (but I will probably pull out the specific run_ids to make this quicker). Lets start with a way to show mean acceleration error when we apply a modle to the testing datasets we've been using (complex_TBP_planar_<1,10,100_test>. So far, we've just been printing these to a table but I would like a more visual way to show these stats. Is there a way that I can elegantly show how the mean acceleration error relates to the feature_layer, output_layer, segment_length, and the training dataset? First I was envisioning a heat map with feature_layer on x and output_layer on y, but this doesn't address the other parameters. It is fine if we need to separate visualization into a few subplots, but I would like to pack as much info as I can in to each subplot. You don't need to use a heatmap, that was just my first thought. any other ideas?

268.6 min was the time for the sweep-2BP-12-10 run
Got a response. To narrow down the analysis we are doing, let's fix a few parameters:
- activation = leaky_relu
- depth = 2
## Latent ODEs
What is a latent ODE?
It is a continuous-time generative model for sequential data that combines ideas from neural ODEs and variational autoencoders. Rather than modeling observed data directly with an ODE, we:
1. Encode the 
# December 10
https://wandb.ai/mlds-lab/neuralODEs/workspace/panel/ds4l5tisv?nw=nwuserswielgosz
![[Pasted image 20251210172521.png]]
I'm surprised by the results above wrt output layer. I expected that mlp_4D_signed would not result in the best results but it has the highest negative correlation. However, if I manually inspect the acceleration this isn't what I see? In general I see gelu and mlp_4D_logmag_unit_softplus or mlp_4D_unit_softplus having the best results.
Follow up to this - the way to interpret this is that while mlp_4D_signed has the "best" correlation, the other output layers may not have the best results on average but they do give the best results in at least one instance. Also, we are not checking if the physics are actually obeyed in the case of mlp_4D_signed. To address this, I'm going to add metrics that record 1) the radial acceleration sign error $\text{sign}(a\cdot r)$ (specifically, the percent of steps where accel points outward instead of inward)  and 2) the angle error between true and predicted acceleration

Immediate things to do:
1. implement the above metrics and rerun a few specific cases
2. take the best cases of acceleration error for each of the output layers and plug these runs into the generalization test
3. same as above, but test how they stack up in the acceleration slope thing

Lowest acceleration error runs from sweep-12-9v3
activation: leaky_relu
batch size: 256
lr_strategy: \[0.001,0.0001\]
steps: \[2000,10\]
segment size [18,18] (5%)
width: 64
depth: 2

1 training orbits:
	mlp_4D_signed:
		run_id:
		accel_error:
	mlp_4D_unit_softplus:
		run_id:
		accel_error:
	mlp_4D_logmag_unit_exp:
			run_id:
			accel_error:
	mlp_4D_logmag_unit_softplus:
			run_id:
			accel_error:

10 training orbits:

activation: leaky_relu
batch size: 256
lr_strategy: \[0.001,0.0001\]
steps: \[500,2000\]
segment size \[5%,5%\] 
width: 64
depth: 2
mlp_4D_signed:
	run_id:  2pcy4ylv
	accel_error: 1.05765
mlp_4D_unit_softplus:
	run_id: ide3ek4b
	accel_error: 1.35937
mlp_4D_logmag_unit_exp:
		run_id: eizi29ws
		accel_error: 1.10677
mlp_4D_logmag_unit_softplus:
		run_id: 9gbf59uo
		accel_error: 1.33087

Testing generalization on the above 4 with 10 orbits:

| label    | wandb_source_id | output_layer                | complex_TBP_planar_1_test (mean) | complex_TBP_planar_1_test (theta-deg) | complex_TBP_planar_1_test (radial%) | complex_TBP_planar_1_test (skewness) | complex_TBP_planar_1_test (pearson-sk1) | complex_TBP_planar_1_test (pearson-sk2) | complex_TBP_planar_1_test (bowley) | complex_TBP_planar_10_test (mean) | complex_TBP_planar_10_test (theta-deg) | complex_TBP_planar_10_test (radial%) | complex_TBP_planar_10_test (skewness) | complex_TBP_planar_10_test (pearson-sk1) | complex_TBP_planar_10_test (pearson-sk2) | complex_TBP_planar_10_test (bowley) | complex_TBP_planar_100_test (mean) | complex_TBP_planar_100_test (theta-deg) | complex_TBP_planar_100_test (radial%) | complex_TBP_planar_100_test (skewness) | complex_TBP_planar_100_test (pearson-sk1) | complex_TBP_planar_100_test (pearson-sk2) | complex_TBP_planar_100_test (bowley) |
| :------- | :-------------- | :-------------------------- | -------------------------------: | ------------------------------------: | ----------------------------------: | -----------------------------------: | --------------------------------------: | --------------------------------------: | ---------------------------------: | --------------------------------: | -------------------------------------: | -----------------------------------: | ------------------------------------: | ---------------------------------------: | ---------------------------------------: | ----------------------------------: | ---------------------------------: | --------------------------------------: | ------------------------------------: | -------------------------------------: | ----------------------------------------: | ----------------------------------------: | -----------------------------------: |
| 2pcy4ylv | 2pcy4ylv        | mlp_4D_signed               |                             4.75 |                                  1.66 |                                   0 |                                0.846 |                                   0.683 |                                   0.771 |                              0.338 |                              7.06 |                                   2.07 |                                    0 |                                  3.03 |                                     0.47 |                                    0.991 |                               0.275 |                               6.12 |                                    1.75 |                                     0 |                                   2.64 |                                     0.726 |                                     0.892 |                                0.238 |
| ide3ek4b | ide3ek4b        | mlp_4D_unit_softplus        |                             5.85 |                                 0.466 |                                   0 |                                0.395 |                                    1.23 |                                   0.437 |                              0.129 |                              14.8 |                                  0.747 |                                    0 |                                  3.51 |                                    0.476 |                                     1.04 |                               0.407 |                               11.7 |                                    0.68 |                                     0 |                                   4.08 |                                     0.568 |                                     0.972 |                                 0.35 |
| eizi29ws | eizi29ws        | mlp_4D_logmag_unit_exp      |                             6.64 |                                 0.622 |                                   0 |                                0.995 |                                    1.05 |                                   0.461 |                             -0.176 |                              12.7 |                                  0.795 |                                    0 |                                  3.38 |                                    0.593 |                                    0.981 |                                 0.3 |                               10.9 |                                   0.824 |                                     0 |                                   2.96 |                                     0.761 |                                     0.943 |                                 0.28 |
| 9gbf59uo | 9gbf59uo        | mlp_4D_logmag_unit_softplus |                             6.02 |                                 0.565 |                                   0 |                                0.389 |                                   0.923 |                                   0.466 |                              0.145 |                              14.7 |                                  0.803 |                                    0 |                                   3.5 |                                    0.481 |                                     1.04 |                               0.408 |                               11.7 |                                   0.713 |                                     0 |                                   4.05 |                                     0.574 |                                     0.976 |                                 0.35 |

![[Pasted image 20251210221220.png]]
![[Pasted image 20251210221317.png]]

What if I try training without the unit?
try mlp_4D_logmag_exp and mlp_4D_softplus, compare to mlp_4D_signed (note that these are all for training on 10 orbits)
mlp_4D_signed: 2pcy4ylv
mlp_4D_softplus run: e8bo4b0h
mlp_4D_logmag_exp run: v27e323a

| label    | wandb_source_id | output_layer      | complex_TBP_planar_1_test (mean) | complex_TBP_planar_1_test (theta-deg) | complex_TBP_planar_1_test (radial%) | complex_TBP_planar_1_test (skewness) | complex_TBP_planar_1_test (pearson-sk1) | complex_TBP_planar_1_test (pearson-sk2) | complex_TBP_planar_1_test (bowley) | complex_TBP_planar_10_test (mean) | complex_TBP_planar_10_test (theta-deg) | complex_TBP_planar_10_test (radial%) | complex_TBP_planar_10_test (skewness) | complex_TBP_planar_10_test (pearson-sk1) | complex_TBP_planar_10_test (pearson-sk2) | complex_TBP_planar_10_test (bowley) | complex_TBP_planar_100_test (mean) | complex_TBP_planar_100_test (theta-deg) | complex_TBP_planar_100_test (radial%) | complex_TBP_planar_100_test (skewness) | complex_TBP_planar_100_test (pearson-sk1) | complex_TBP_planar_100_test (pearson-sk2) | complex_TBP_planar_100_test (bowley) |
| :------- | :-------------- | :---------------- | -------------------------------: | ------------------------------------: | ----------------------------------: | -----------------------------------: | --------------------------------------: | --------------------------------------: | ---------------------------------: | --------------------------------: | -------------------------------------: | -----------------------------------: | ------------------------------------: | ---------------------------------------: | ---------------------------------------: | ----------------------------------: | ---------------------------------: | --------------------------------------: | ------------------------------------: | -------------------------------------: | ----------------------------------------: | ----------------------------------------: | -----------------------------------: |
| 2pcy4ylv | 2pcy4ylv        | mlp_4D_signed     |                             4.75 |                                  1.66 |                                   0 |                                0.846 |                                   0.683 |                                   0.771 |                              0.338 |                              7.06 |                                   2.07 |                                    0 |                                  3.03 |                                     0.47 |                                    0.991 |                               0.275 |                               6.12 |                                    1.75 |                                     0 |                                   2.64 |                                     0.726 |                                     0.892 |                                0.238 |
| e8bo4b0h | e8bo4b0h        | mlp_4D_softplus   |                             9.64 |                                  3.94 |                                   0 |                                0.566 |                                 -0.0573 |                                   0.198 |                             -0.038 |                              14.3 |                                   7.11 |                                 2.25 |                                  4.42 |                                    0.441 |                                     0.89 |                               0.348 |                               12.7 |                                    5.15 |                                 0.775 |                                   5.25 |                                     0.514 |                                     0.817 |                                0.299 |
| v27e323a | v27e323a        | mlp_4D_logmag_exp |                             10.2 |                                  3.47 |                                   0 |                                0.211 |                                 0.00766 |                                   0.198 |                             0.0522 |                              13.9 |                                   5.71 |                                0.917 |                                  3.78 |                                    0.425 |                                    0.963 |                               0.373 |                               12.5 |                                    4.86 |                                 0.614 |                                   4.69 |                                     0.572 |                                     0.836 |                                 0.27 |
We also don't have validation data at each step, but we are running
100 training orbit:

activation: leaky_relu
batch size: 256
lr_strategy: \[0.001,0.0001\]
steps: \[2000,10\]
segment size [18,18] (5%)
width: 64
depth: 2

mlp_4D_signed:
	run_id: fv65gils
	accel_error: 1.36058
mlp_4D_unit_softplus:
	run_id: 11rpegww
	accel_error: 1.61113
mlp_4D_logmag_unit_exp:
		run_id: ae16kn8c
		accel_error: 1.83989
mlp_4D_logmag_unit_softplus:
		run_id: zz7b0mty
		accel_error: 1.58358

| label    | wandb_source_id | output_layer                | complex_TBP_planar_1_test (mean) | complex_TBP_planar_1_test (theta-deg) | complex_TBP_planar_1_test (radial%) | complex_TBP_planar_1_test (skewness) | complex_TBP_planar_1_test (pearson-sk1) | complex_TBP_planar_1_test (pearson-sk2) | complex_TBP_planar_1_test (bowley) | complex_TBP_planar_10_test (mean) | complex_TBP_planar_10_test (theta-deg) | complex_TBP_planar_10_test (radial%) | complex_TBP_planar_10_test (skewness) | complex_TBP_planar_10_test (pearson-sk1) | complex_TBP_planar_10_test (pearson-sk2) | complex_TBP_planar_10_test (bowley) | complex_TBP_planar_100_test (mean) | complex_TBP_planar_100_test (theta-deg) | complex_TBP_planar_100_test (radial%) | complex_TBP_planar_100_test (skewness) | complex_TBP_planar_100_test (pearson-sk1) | complex_TBP_planar_100_test (pearson-sk2) | complex_TBP_planar_100_test (bowley) |
| :------- | :-------------- | :-------------------------- | -------------------------------: | ------------------------------------: | ----------------------------------: | -----------------------------------: | --------------------------------------: | --------------------------------------: | ---------------------------------: | --------------------------------: | -------------------------------------: | -----------------------------------: | ------------------------------------: | ---------------------------------------: | ---------------------------------------: | ----------------------------------: | ---------------------------------: | --------------------------------------: | ------------------------------------: | -------------------------------------: | ----------------------------------------: | ----------------------------------------: | -----------------------------------: |
| fv65gils | fv65gils        | mlp_4D_signed               |                              1.6 |                                 0.553 |                                   0 |                                0.767 |                                    0.43 |                                   0.519 |                             0.0923 |                              1.81 |                                  0.477 |                                    0 |                                  3.67 |                                    0.423 |                                     0.91 |                               0.319 |                               1.55 |                                   0.436 |                                     0 |                                   3.79 |                                     0.507 |                                     0.752 |                                0.209 |
| 11rpegww | 11rpegww        | mlp_4D_unit_softplus        |                              1.3 |                                 0.302 |                                   0 |                                0.954 |                                    1.08 |                                   0.838 |                              0.211 |                              3.03 |                                  0.342 |                                    0 |                                  3.66 |                                      0.5 |                                    0.986 |                               0.321 |                               2.22 |                                   0.336 |                                     0 |                                   3.72 |                                     0.655 |                                     0.871 |                                0.265 |
| ae16kn8c | ae16kn8c        | mlp_4D_logmag_unit_exp      |                             2.19 |                                 0.232 |                                   0 |                                0.485 |                                   0.585 |                                    0.45 |                              0.216 |                              3.49 |                                  0.329 |                                    0 |                                  3.39 |                                    0.425 |                                     1.02 |                               0.373 |                               2.38 |                                   0.339 |                                     0 |                                   4.11 |                                     0.576 |                                     0.891 |                                0.295 |
| zz7b0mty | zz7b0mty        | mlp_4D_logmag_unit_softplus |                             1.45 |                                 0.292 |                                   0 |                                0.752 |                                   0.176 |                                   0.575 |                              0.214 |                              2.71 |                                  0.333 |                                    0 |                                  3.76 |                                    0.499 |                                    0.969 |                               0.305 |                               2.05 |                                   0.338 |                                     0 |                                   3.98 |                                     0.471 |                                     0.837 |                                0.263 |
|          |                 |                             |                                  |                                       |                                     |                                      |                                         |                                         |                                    |                                   |                                        |                                      |                                       |                                          |                                          |                                     |                                    |                                         |                                       |                                        |                                           |                                           |                                      |
![[Pasted image 20251210222559.png]]
![[Pasted image 20251210222819.png]]

Statistics being recorded:
- Mean
- Skewness
	$\text{skewness} = \frac{E[(x - \mu)^3]}{\sigma^3}$ 
	- `finite` = $x$
	- `mean` = $\mu$
	- `std` = $\sigma$
	- `centered`= $(x - \mu) / \sigma$
	- `centered**3` =  $(x - \mu)^3 / \sigma^3$
	- `np.mean(centered**3)` = $E[(x - \mu)^3] / \sigma^3$

| **Symbol**    | **Name**           | **Meaning**                       |
| ------------- | ------------------ | --------------------------------- |
| $x$           | Observed value     | Each data point in your array     |
| $\mu$         | Mean               | Average of all values             |
| $\sigma$      | Standard deviation | Spread of the data                |
| $E[\cdot]$    | Expectation (mean) | Average over all samples          |
| $(x - \mu)^3$ | Cubed deviation    | Measures asymmetric tail behavior |

Attemtping with a spherical harmonics transform:

| label    | wandb_source_id   | output_layer           |   complex_TBP_planar_1_test (mean) |   complex_TBP_planar_1_test (theta-deg) |   complex_TBP_planar_1_test (radial%) |   complex_TBP_planar_1_test (skewness) |   complex_TBP_planar_1_test (pearson-sk1) |   complex_TBP_planar_1_test (pearson-sk2) |   complex_TBP_planar_1_test (bowley) |   complex_TBP_planar_10_test (mean) |   complex_TBP_planar_10_test (theta-deg) |   complex_TBP_planar_10_test (radial%) |   complex_TBP_planar_10_test (skewness) |   complex_TBP_planar_10_test (pearson-sk1) |   complex_TBP_planar_10_test (pearson-sk2) |   complex_TBP_planar_10_test (bowley) |   complex_TBP_planar_100_test (mean) |   complex_TBP_planar_100_test (theta-deg) |   complex_TBP_planar_100_test (radial%) |   complex_TBP_planar_100_test (skewness) |   complex_TBP_planar_100_test (pearson-sk1) |   complex_TBP_planar_100_test (pearson-sk2) |   complex_TBP_planar_100_test (bowley) |
|:---------|:------------------|:-----------------------|-----------------------------------:|----------------------------------------:|--------------------------------------:|---------------------------------------:|------------------------------------------:|------------------------------------------:|-------------------------------------:|------------------------------------:|-----------------------------------------:|---------------------------------------:|----------------------------------------:|-------------------------------------------:|-------------------------------------------:|--------------------------------------:|-------------------------------------:|------------------------------------------:|----------------------------------------:|-----------------------------------------:|--------------------------------------------:|--------------------------------------------:|---------------------------------------:|
| 2pcy4ylv | 2pcy4ylv          | mlp_4D_signed          |                               4.75 |                                   1.66  |                                     0 |                                  0.846 |                                     0.683 |                                     0.771 |                               0.338  |                                7.06 |                                    2.07  |                                      0 |                                    3.03 |                                      0.47  |                                      0.991 |                                 0.275 |                                 6.12 |                                     1.75  |                                       0 |                                     2.64 |                                       0.726 |                                       0.892 |                                  0.238 |
| ide3ek4b | ide3ek4b          | mlp_4D_unit_softplus   |                               5.85 |                                   0.466 |                                     0 |                                  0.395 |                                     1.23  |                                     0.437 |                               0.129  |                               14.8  |                                    0.747 |                                      0 |                                    3.51 |                                      0.476 |                                      1.04  |                                 0.407 |                                11.7  |                                     0.68  |                                       0 |                                     4.08 |                                       0.568 |                                       0.972 |                                  0.35  |
| eizi29ws | eizi29ws          | mlp_4D_logmag_unit_exp |                               6.64 |                                   0.622 |                                     0 |                                  0.995 |                                     1.05  |                                     0.461 |                              -0.176  |                               12.7  |                                    0.795 |                                      0 |                                    3.38 |                                      0.593 |                                      0.981 |                                 0.3   |                                10.9  |                                     0.824 |                                       0 |                                     2.96 |                                       0.761 |                                       0.943 |                                  0.28  |
| v3knp5vs | v3knp5vs          | mlp_4D_logmag_unit_exp |                               6.09 |                                   0.713 |                                     0 |                                  1.17  |                                     1.04  |                                     0.552 |                               0.0314 |                               14    |                                    1.03  |                                      0 |                                    3.89 |                                      0.46  |                                      0.973 |                                 0.39  |                                 9.88 |                                     0.931 |                                       0 |                                     4.06 |                                       0.54  |                                       1.04  |                                  0.448 |

To do:
- [ ] test mlp_4D_signed_unit
- [ ] evaluate log log space for the models specified
- [ ] redo heat map
- [ ] what happens when we test on the training datasets?
- [ ] record spread of data
	- [ ] outliers
	- [ ] mean, median, standard deviation
	- [ ] skewness 
- [ ] record the new physics aware metrics:
	- [ ] angle error 
	- [ ] radial acceleration sign error
- [ ] try different input layers

Things I want to test:
- input layers
- output layers
- segmentation strategy
- is generalization improved with

Let's do a 
# December 9

## speed vs sweep crash issues
Fixed issues with sweep crashing, but now it is running very slowly because I think I limited resources too much. Specifically, these are the flags I currently have:
``` python
ray.init(
            num_cpus=16,  # or another cap below your physical core count
            runtime_env={
                "env_vars": {
                    "JAX_PLATFORM_NAME": "cpu",
                    "CUDA_VISIBLE_DEVICES": "",
                    "OMP_NUM_THREADS": "1",
                    "MKL_NUM_THREADS": "1",
                    "XLA_FLAGS": "--xla_cpu_multi_thread_eigen=false intra_op_parallelism_threads=1",
                },
            },
        )
```
Explanation: 
- `OMP_NUM_THREADS` controls OpenMP, which is used by many low-level C/C++ numerical libraries which prevents multi-core parallelism in SciPy internal and parts of NumPy (and maybe jax or diffrax?)
- `MKL_NUM_THREADS` controls the Intel Math Kernel Library, which is used heavily in numpy, scipy, scikit-learn, parts of pytorch
- `"XLA_FLAGS": "--xla_cpu_multi_thread_eigen=false intra_op_parallelism_threads=1"` affects XLA which is the compiler backend for JAX (and tensorflowXLA and parts of PyTorch)
	- It controls how Eigen (CPU math backend) is threaded
	- `--xla_cpu_multi_thread_eign=false` disables multi-threaded Eigen kernels and forces XLA CPU ops to be single-threaded
		- Without this, XLA will internally parallelize matrix ops across cores
	- `intra_op_parallelism_threads=1` limits threads used within a single XLA operation. It prevents a single large matmul from suddenly spawning many threads

Difference between ray.int(num_cpus=16) and ray.remote(num_cpus=4) is that num_cpus in ray.init sets the cluster-wide CPU capacity Ray should schedule against (how many logical CPU slots are available) and num_cpus in ray.remote sets how many of those slots a particular task reserves while it runs. ray.init declares the pool size, num_cpus declares each job's requirement

But now we use at most 4 concurrent workers (16 cpus from ray.init/4 cpus per process from ray.future) out of the 96 available which is stupid and kills the parallel speed

Factors that were probably causing OOM:
	•	JAX (via XLA) spawns a big threadpool, often ~#cores, for each process.  ￼
	•	You launch many Ray workers in parallel.
	•	Each worker:
	•	Loads a big dataset from W&B,
	•	Allocates JAX arrays for training,
	•	And tries to use many CPU threads.

Even if you set num_cpus in Ray, JAX does not automatically respect that; it happily uses lots of OS threads unless you clamp it with XLA_FLAGS. So you get:
	•	Too many threads
	•	Too many resident arrays
	•	→ RSS explodes → system OOM or Ray ObjectStoreFullError.

Your “threads=1” fix solved that by under-utilizing the machine.

Knobs we care about:
- Threads per JAX training run
``` python
XLA_FLAGS="--xla_cpu_multi_thread_eigen=false intra_op_parallelism_threads=N"
OMP_NUM_THREADS=1
MKL_NUM_THREADS=1
```
- Number of concurrent sweep runs:
	Controlled approximately by Ray with
```
@ray.remote(num_cpus=CPUS_PER_RUN)
ray.init(num_cpus=TOTAL_CPUS_FOR_RAY, ...)
```
Concurrency ~= TOTAL_CPUS_FOR_RAY / CPUS_PER_RUN

We want to avoid JAX using all cores per run and ray launching tons of runs
Trying to limit my consumption to ~ 60 logical threads
`num_cpus=64` in Ray means 64 logical CPUs, which means 64 hardware threads (not physical cores). CPUs are interpreted by ray as the logical CPUs reported by the OS via `nproc`, which for us is 192. It has not concept of physical core vs SMT thread

``` python
# How many CPUs total Ray can use in a batch
num_cpus_total = int(os.environ.get("RAY_SWEEP_CPUS", 64))

# Must match @ray.remote(num_cpus=8)
cpus_per_worker = 8

# Optimal number of parallel jobs in one Ray cluster
batch_size = num_cpus_total // cpus_per_worker
```
## memory issues with /tmp/ray
artifacts are being saved to /tmp/ray/ which took up all the memory. We need to prevent this. `sweep.py` currently runs everything under one long-lived Ray session and all configs are launched at onces, so /tmp/ray grows because that session spills and logs there and we can't delete inside /tmp/ray while it's running. To reclaim space during a sweep, we may need to run in batches and restart ray between batches so the session temp dir is cleaned which will keeps the sweep going, but each batch starts fresh and cleans its temp:
``` python
from itertools import islice

def chunks(seq, n):
    it = iter(seq)
    while True:
        batch = list(islice(it, n))
        if not batch:
            break
        yield batch

for batch in chunks(configs, 4):  # 4 runs at a time, adjust as needed
    ray.init(num_cpus=8, temp_dir="/path/with/space")  # point temp_dir/RAY_TMPDIR to a roomy disk
    futures = [main.remote(cfg) for cfg in batch]
    ray.get(futures)
    del futures  # drop refs so spilled objects can be freed
    ray.shutdown()  # ends the session and deletes its /tmp/ray/session_* dir
```

- We can also throttle concurrency to reduce spills - lower `num_cpus` in ray.init and/pr raise `num_cpus` per task so fewer run at once. Smaller batches and smaller per-task memory also reduce spill pressure.
- we could also redirect spill/temp to a larger location instead of /tmp but I think this is the worst idea because then we may still run into disk space issues just in a different directory
``` python
import json
ray.init(
    temp_dir="/path/with/space",  # or set RAY_TMPDIR env var
    _system_config={
        "object_spilling_config": json.dumps({
            "type": "filesystem",
            "params": {"directory_path": "/path/with/space/ray_spill"}
        })
    },
    num_cpus=8,
)
```
Spilled files tied to live objects disappear once those objects are freed; leftovers mainly come from crashed sessions.

Spill files created during a healthy run are tied to live Ray objects; once those objects are freed and the session ends cleanly, Ray deletes them. The big piles you saw are usually from sessions that crashed or were killed before cleanup ran. If a task crashes but the Ray process stays up, the session stays alive and its spill dir sticks around until the session ends; if the whole session dies abruptly, the spill dir is orphaned.

Changing your sweep to catch task errors helps avoid full-session crashes, but won’t stop spill files from being created while the session runs. They’ll still persist until the session shuts down (or until the objects are freed and Ray cleans up). To prevent /tmp/ray from accumulating across crashes, you need to:

- Ensure sessions shut down cleanly (e.g., batching work and calling ray.shutdown() between batches).
- Remove orphaned session_* dirs when no Ray process is running (e.g., ray stop && rm -rf /tmp/ray/session_*).
- Reduce spills (fewer/lighter objects, lower concurrency) or redirect them to a larger location with RAY_TMPDIR / temp_dir + object_spilling_config.

To monitor this, we need to do the following (because the ray/tmp will be in docker container NOT host system):
```
docker exec -it <CONTAINER_ID> /bin/bash
ls -ld /tmp /tmp/ray/
```
and our container ID is currently 383317d51f70 (but we can find with `docker ps` or `docker ps -a` if it is stopped)
and we can check the disk space via `du -sh /tmp`
I've noticed a lot of wandb artifacts which we can delete from tmp with ```rm -rf /tmp/wandb-*
rm -rf /tmp/tmp*wandb-*```
If these become an issue we may want to do:
``` python
import glob
import shutil

# ... your code ...

ray.shutdown()  # stop Ray, workers, object store, etc.

# Clean up leftover W&B temp dirs in this environment
for path in glob.glob("/tmp/wandb-*") + glob.glob("/tmp/tmp*wandb-*"):
    shutil.rmtree(path, ignore_errors=True)
    ```

## Recap of all things speed and space related:
`"XLA_FLAGS": "--xla_cpu_multi_thread_eigen=false"` this forces JAX/XLA’s CPU backend to run its Eigen-based linear algebra in a single thread instead of using its internal thread pool.
When you run JAX on CPU:
	•	Your Python code → JAX → XLA compiler
	•	XLA generates CPU code that uses Eigen (a C++ linear algebra library)
	•	By default:
	•	Eigen spawns its own thread pool
	•	It parallelizes matrix multiplies, convolutions, etc.

So without the flag, each JAX process will try to multithread internally. This prevents oversubscription - each process would otherwise spawn dozens of BLAS/XLA threads. As far as I can tell, `intra_op_parallelism_threads=1` does NOT exist for JAX. It is used for tensorflow, so does not apply for us. Unfortunately, there is no way we can specify how many threads Eigen can use. So, either we are single threaded or we are leaving JAX to multithread internally. 
I had set OMP_NUM_THREADS and MKLNUM_THREADS=1, which in combination with setting multi-thread = false means we are using a single thread for every model that we train. 

Big error that I discovered: we had a single ray sweep running. None of the temporary files that were in tmp/ray/ were deleted, so we ended up with ~800 GB of temporary files. When we run out of disk space, the sweep crashes and Docker crashes and everything crashes. To get around this, we can batch how many ray jobs (how many model trainings) we launch in one wave. By doing this, we give the code a chance to delete temporary files:
``` python
futures = [main.remote(config) for config in batch]
            ray.get(futures)
            del futures  # drop refs so spilled objects can be freed
            ray.shutdown()
```
ray.init(num_cpus=TOTAL_CPUS) defines how many total CPU slots are available for scheduling tasks. ray.remote(num_cpus=CPUS_PER_WORKER) specifies the number of CPU slots for each main job. Let's say that TOTAL_CPUS=64 and CPUS_PER_WORKER=4. This means Ray can run at most 64/4=16 concurrent workers. Then batch_size specifies how many models to run before we stop ray and restart, which is for the purpose of clearing /tmp. If we set batch_size = WORKERS_PER_BATCH = TOTAL_CPUS/CPUS_PER_WORKER (=16 in our example) that means that each batch fully saturates the machine. If batch_size < WORKERS_PER_BATCH, we're underutilizing CPUs. If batch_size > WORKERS_PER_BATCH, Ray can only run as many as specified by the num_cpus limits and other runs would get queued and may sit in /tmp longer. 

So the question: do these flags
``` python
"OMP_NUM_THREADS": "1",
"MKL_NUM_THREADS": "1",
"XLA_FLAGS": "--xla_cpu_multi_thread_eigen=false",
```
preotect us from the large /tmp and OOM issues? Not rally - they control threading and CPU parallelism, not how much JAX allocates in RAM, how much Ray spills to /tmp, how much W&B writes to disk. The large /tmp and OOM could be driven by too many concurrent workers/runs, Ray object store and spilling, big JAX arrays and datasets per worker, W&B artifacts and temp files. 

OOM error is about memory (RAM/GPU), not CPU. The bloat in /tmp is a sign that we were under memory pressure and used Ray's object spilling. The new strategy:
•	batching sweeps (\_batched(configs, batch\_size))
•	ray.shutdown() between batches
•	cleaning /tmp/ray-* and /tmp/wandb-* at the end
is (allegedly) what protects us from previous explosion. The thread flags are not the main safety net for OOM. 

What the flags end up doing: 
- OMP_NUM_THREADS and MKL_NUM_THREADS control how many threads BLAS / MKL / OMP-based code uses inside each process. 
- XLA_FLAGS=--xla_cpu_multi_thread_eigen=false tells XLA’s CPU backend not to spin up its own multi-threaded Eigen pool (basically “don’t multi-thread JAX ops”).
So, with 
``` python
num_cpus=TOTAL_CPUS  # 64
CPUS_PER_WORKER = 4
@ray.remote(num_cpus=4)
```
we get up to 16 workers in parallel. But if we also have OMP_NUM_THREADS and MKL_NUM_THREADS set to 1, each worker is single-threaded so total effective CPU concurrency ~= 16 threads when we allowed 64. This means we are underutilizing compute and have slower runs If you remove those flags and let defaults be (say, 8–64 threads per worker), you risk **oversubscription** (e.g. 16 workers × 64 threads = 1024 threads), which is bad for performance but still not the primary cause of major OOM. 

So how can we speed up? It's reasonable to relax the flags to get some speed back - drop the XLA flags because this can hurt performance a lot on heavy linear algebra. If runs are still slower than desired, we can relax OMP/MKL a bit. Keep the batching and cleanup. We should probably also add a cleanup for temp wandb files. If don't set --xla_cpu_multi_thread_eigen to false, then XLA enables multi-threading by default. It will choose the number of threads using its own heuristics, usually via something like number of logical cores visible to the process. It doesn't care about OMP or MKL settings - these don't affect XLA/Eigen. Codex suggests `--xla_cpu_multi_thread_eigen_num_threads=4"` but this doesn't actually exist. 

If we set OMP=N and MKL=M threads, they will not use different threads from each other. They just tell the libraries don't spawn more than N or M threads. The IS scheduler will place those threads on whicever cores are available. But if we let XLA determine its number of threads, we can oversubscribe. 
To do:
- [ ] increase speed of run without overwhelming computer
- [ ] increase latent ODE understanding, particularly which knobs to 

tmux to keep runs running
logan suggested mapping to higher frequency input

Usually no immediate crash—just heavy contention and slowdown. But oversaturating can trigger secondary failures:

- Too many tasks/threads → high context switching, wall time spikes; Ray tasks may time out.
- Extra threads can increase memory use; if you hit OOM, the OS/Ray will kill workers or the process.
- If you exceed cgroup/cpuset CPU quota, tasks just get throttled; not a crash, just slower.

To stay safe: keep Ray’s num_cpus at/under your logical cores, cap per-task num_cpus accordingly, and limit thread pools (OMP_NUM_THREADS, MKL_NUM_THREADS, XLA flags). If you see kills/OOMs, lower concurrency rather than disabling limits.

tmux:
List sessions, then attach:

- List: tmux ls
- Attach: tmux attach -t <session_name_or_id>

If there’s only one session, tmux attach will grab it. If a session is detached but named (e.g., you started with tmux new -s sweep), use that name: tmux attach -t sweep.
# December 8
Last night I fixed some of the sweep config capabilities in `make_all_configs` - previously when I created multiple configs using make_all_configs, values from the sweep config would not overwrite those from the default config unless there were 2+ entries. For example, if I specified a batch size of 64 in the default config and a batch size of 32 in the sweep config, the model would use 64 instead of 32. However, if the sweep config specified \[16, 32\], then the values would be properly overwritten. I ran a fairly large sweep with ~6000 models, but it only went through ~360 models before bailing. 

One of the failure modes is that configs with segment lengths that produce zero usable segments will raise ValueError in train_model and terminate the sweep. Example: suppose your dataset has one orbit with 120 time steps, but the last 30 steps are NaN (padding). If a config uses segment_length_strategy: [200] (or even 120) then in segment_data every attempted segment either overshoots the orbit length or includes NaNs, so zero segments are emitted. train_model then hits ValueError: Segment length 200 produced no usable trajectory segments. Because it’s a Ray task, that exception bubbles up and stops the sweep. 

I wonder if there's a way to update this so the whole thing doesn't crash just because of bad training?
I would also like the capability to compare configs and display which parameters are different betwen configs. 
What does the artifact return?
Do we still need data_shape to be passed to the model or did we fix this?

Let's update our sweep so that if a run fails, the sweep doesn't crash.
I have a list_crashed_runs script that now lists all the crashed run_ids from a group. I' trying to figure out where the issue occurs. Once we get the sweep updated so that we don't crash from one run, use one of these "bad" runs to cause a crash
This is fixed but too slow with the limits, I htink on the XLA stuff

None of the wandb logs really say anything useful. They're all like this:
```
2025-12-07 22:58:44
Wandb initialized with project: neuralODEs, entity: mlds-lab
2025-12-07 22:58:45
wandb:   1 of 1 files downloaded.
2025-12-07 22:58:45
Only one orbit available, no split performed.
2025-12-07 22:58:45
 Validation set will be the same as training set!
2025-12-07 22:58:45
Training progress:  48%|████▊     | 1201/2500 [01:14<01:29, 14.49step/s]
```
My assumption is that a run crashed due to integration errors and this crashed the whole sweep. 

Goals:
- [ ] Get sweep set up so that failure of a run does not mean failure of the whole sweep
- [ ] Visualizations
- [ ] Get latent ODE set up.

## Latent ODEs
Referencing Patrick Kidger's tutorial: https://docs.kidger.site/diffrax/examples/latent_ode/

What is a latent ODE? 
# December 5

Recap: we were trying to find an output layer that performed better than the original mlp_4D_signed used in the conference since this had a failure mode that has been previously discussed. When we predict the log of the acceleration, we get better generalization abilities:
``` python
def mlp_4D_logmag_unit_exp(mlp_output, state, scalar=1.0, eps=1e-8):
    """True log-magnitude with exp; direction normalized without tanh."""

    log_r_mag = mlp_output[0:1]
    r_mag = scalar * jnp.exp(log_r_mag)

    r_dir = mlp_output[1:4]
    r_dir_mag = jnp.linalg.norm(r_dir) + eps
    r_dir_unit = r_dir / r_dir_mag

    acc_pred = r_mag * r_dir_unit
    return jnp.concatenate((state[3:6], acc_pred), axis=0)
```
We get better generalization capabilities than mlp_4D_signed using the above output layer, at least in the config we were using which was lofi, 2000 steps, leaky_relu, segment length = 18, etc (details can be found in yesterday's notes).

Things to work on:
- [ ] Sensitivity analysis and visualizations
	- [ ] brainstorm new visualizations
	- [ ] set up sweep and ensure everything works as expected
	- [ ] implement some visualizations
- [ ] clean code and commit
- [ ] can we see if shorter segment lengths produces  linear results?
- [ ] fix the issue where certain params don't get overwritten even if they are specified in the sweep yaml
## Box and whisker plot
The point of this is to view the distribution of the accelerat

When we calculate acceleration error, we are taking an initial condition, propagating for the entire orbit and then evaluating acceleration error at each timestep of each validation orbit where the timesteps are exactly the dataset timesteps. Re: box and whisker plot - we currently show acceleration error at every timestep of every orbit in the validation dataset. A better idea may be to instead calculate the average acceleration error per orbit (i.e. over all timesteps in an orbit), and use these values to create our box and whisker plot.  

## Are results linear?
When we load training data, we load some number of orbital trajectories where each has associated time series data. Currently, each orbit has 360 datapoints corresponding to one degree increments of mean anomaly. We have state data (position and velocity) and the time at each step. We found that to get better training results, we must segment the orbit into multiple trajectories. For example, if we define a segment length to be 18 (out of 360 total points), then that means we get 20 trajectories from each orbit. We had to do this because if the segments were too long (equivalently, if we use the whole orbit) then we get a vanishing gradient and the model doesn't learn anything. Based on this, we hypothesize that shorter segments = better training. However, I'm wondering if we may get to a point where segments are so short that we really just approximate linear dynamics. How could we test this, either through numerical or visual analysis? 

## Update:

Updates:
- We've been using mean acceleration error across all validation orbits and timesteps  as our error metric. I was curious to see at a more granular level what this distribution looked like. This is an example of a box and whisker plot where error at each orbit and each timestep is used to compute statistics. This shows error after training on 10 complex orbits, and testing on the specified validation datasets. The solid horizontal line is the median, dashed horizontal line is the mean, and the red points (those are markers and not lines, there's just a lot) are the outliers, defined as points below Q1 - 1.5*\IQR (interquartile range) or above Q3 + 1.5\*IQR.  Our distribution is right-skewed which is not super surprising, but it would be interesting to perhaps even break this down by orbit to see where the model struggles the most. We expect this to be high eccentricity and SMA. I want to extend this analysis to sweeps of models in some forms - perhaps certain pipelines/models are better to minimize the spread.

![[Pasted image 20251205172803.png]]

I was wondering if smaller segmentation lengths ever produce linear behavior. True 2BP dynamics should have a slope of -2 in loglog space. The largest SMA in the training dataset is indicated by the vertical dashed red line to show the bounds. The legend indicates what percent of the complete orbit is represented by each segment. It's intersting that in many cases, there seems to be a critical radius around 4R_E where the dynamics are proprtional to 1/r rather than 1/r^2. At least with this config, there isn't a clear relationship between segment ratio and the slope. For example, here a segment ratio of 10% has the most accurate aproximate slope (where the slope is just the first coefficient from a straight-line fit in log-log space). Does this mean anything/will these results persist in other configurations? Not sure, will investigate further.
![[Pasted image 20251205172815.png]]
Over the weekend I'm planning to run some large-ish sweeps so I can do more analysis on Monday and get a better picture of global trends that may or may not exist. 
# December 4
Recap:
- We discovered a failure mode where predicted acceleration direction can flip 180 degrees. Our mlp output was acceleration value and its direction, but this is not a good output because $a\times\hat{a} = -a\times -\hat{a}$. We hypothesized that fixing this would result in better training and/or generalization, but so far we have not been seeing this.
- This is in part because if we only modify the output layer to be |a| and $\hat{a}$, we now have the correct sign of direction but the model could predict a or -a and get the same output, which may confuse the network - non-uniqueness might be causing trouble. abs value is also non differentiable. We switched to softplus(acc) and see smoother convergence than either signed or abs acc results, but losses are still higher than signed which is perplexing. However, note that the aforementioned failure mode was not seen. I want to figure out when this failure actually occurs.
	- We may want different activation functions or feature representations
- In general, regardless of loss function we would expect the acceleration to be better than it is
- We often see that acceleration begins to point radially relative to its true direction , peaking at periapsis. The predicted acceleration is still opposite the predicted direction, i.e. the predicted theta is 180 degrees, but predicted acceleration is radial compared to true acceleration vector. Acceleration direction changes most quickly at periapsis so I am not surprised it is having trouble here, but I would like to mitigate this. 

## Testing input/output features, activation functions
Is there a better final activation we can use? Maybe better input or output features?
We originally had our mlp produce 4 outputs, which were taken to be the acceleration's value and its unit vector components in x, y, and z. However, this was problematic because $a\times\hat{a} = -a\times -\hat{a}$. We hypothesized that fixing this would result in better training and/or generalization, but so far we have not been seeing this. We tried our output layer taking the absolute value of the first component to ensure that acceleration is positive, but this is problematic because a) absolute value is not differentiable and b), the model could predict a or -a and get the same output, which may confuse the network - non-uniqueness might be causing trouble. We used softplus instead since it is unique to ensure that acceleration always has a positive value.

Questions:
- Currently, a final activation of softplus is applied to the acceleration value, and tanh can be applied to each of the unit vector components but is not for the baseline comparison. Are there better final activations?
- Are we using the best input features? We use 1/r, x/r, y/r, z/r, vx, vy, vz. I think x/r y/r z/r essentially equates to polar coordinates? Maybe not - draw this out
- Are we using the best output features? We output the acceleration value and its direction components. We know this because we take acceleration = a*\hat{a}, and this acceleration vector is what represents the dynamics and gets integrated to compute loss
- Is there a way we can avoid the acceleration turning radial?

Changes and ideas:
- First, let's change our loss back to percent error + rmse. This has been shown to consistently give better results than percent error.
- Re: activations:
	- Magnitude activation: keep positivity but improve conditioning by predicting log_acc and mapping with jnp.exp(log_acc) or jnn.softplus(log_acc) + eps. Training the network on the log of the target magnitude often stabilizes large dynamic ranges and removes the sign ambiguity you saw with abs. If you know a reasonable max accel, a sigmoid scaled to that range can also help.
	- Direction activation: normalize the direction vector explicitly (use mlp_4D_unit/mlp_4D_unit_scaled) and add a small epsilon to the norm to avoid NaNs; optional tanh before normalization to prevent exploding norms. This removes the magnitude–direction entanglement and the ± ambiguity.
		- why would we tanh before normalization?
- Re output features:
	- Orthogonal basis: instead of x/y/z components, output acceleration in a physically defined basis such as RTN/RSW (radial, transverse, normal). Build the basis from the current state, predict three unconstrained scalars, then rotate back to Cartesian; this fixes the sign convention because the basis is uniquely determined by (r, v).
- Re: input features: 
	- we currently use direction cosines, inverse radius, and velocity
	- consider adding - Radial and transverse velocity: vr = <r_hat, v>, vt = |r×v|/|r| (and optionally the normal component), so the network sees how motion splits along/orthogonal to r_hat.
		- is radial and normal not the same?
Overall suggestions: if you stay with magnitude+direction, normalize the direction and learn log‑magnitude; if you switch to RTN components, you can output three unconstrained scalars and skip special activations. If simplicity wins, predict the Cartesian acceleration directly (3 outputs) and drop the magnitude/direction split—the solver still receives the correct vector without ambiguity. Natural next experiments:
1. Swap to a log‑magnitude head (mag = exp(log_mag)) plus direction normalization with epsilon.
2. Try RTN outputs using a basis from (r, v) and predict a_r, a_t, a_n.
3. Add vr/vt (and maybe |h|) to the feature layer and see if generalization improves.


Our hope is to improve generalization ability while training on fewer orbits. Let's get some baseline results. Training on 10 complex orbits, testing mlp_4D and mlp_4D_softplus (where softplus is only applied to the acceleration output):
config:
``` python
wandb:
  group: "complex-lofi-debug"  # Change this to your desired group name

data:
  dataset_name : "complex_TBP_planar_10_train"
  problem: '2BP'

data:
  dataset_name : "complex_TBP_planar_10_train"
  problem: '2BP'

parameters:

  length_strategy:
                      [[
                        [0.0, 1.0],
                      ]]
  lr_strategy: [[0.001]]
  steps_strategy: [[1000]]
  segment_length_strategy: [[18,]]

  width: 64
  depth: 2
  train_val_split: 1.0
  batch_size: 256
  num_trajs: -1

  # loss_fcn: "mean_squared_error"
  loss_fcn: "percent_error"
  # loss_fcn: "percent_error_plus_nmse"

  # activation: tanh
  activation: leaky_relu
  # activation: elu

  feature_layer: sph_4D_rinv_vel
  # feature_layer: sph_4D_rinv_vinv
  output_layer: mlp_4D_signed
  # output_layer: mlp_4D_unit_scaled
  # output_layer: mlp_simple
  planar_constraint: true

  rtol: 0.000001
  atol: 0.00000001
  ```
 **mlp_4D_signed with percent error loss:**
 run_id: snw96q4r
 runtime: 1:32
 
**mlp_4D_accsoftplus with percent error loss:**
run_id: weirulst
runtime: 1:39

**mlp_4D_signed with percent error plus rmse loss:**
run_id: vejpt8p8
runtime: 1:55

**mlp_4D_accsoftplus with percent error plus rmse loss:**
run_id: 06n0t40m
runtime: 1:53

The following results are the average acceleration error on separate validation datasets of 1, 10, 100 orbits:

| label    | output        | loss          | wandb_source_id | complex_TBP_planar_1_test | complex_TBP_planar_10_test | complex_TBP_planar_100_test |
| :------- | :------------ | :------------ | :-------------- | ------------------------: | -------------------------: | --------------------------: |
| snw96q4r | mlp_4D_signed | percent error | snw96q4r        |                      4.61 |                       5.93 |                        5.38 |
| weirulst | softplus      | percent error | weirulst        |                      10.4 |                       10.5 |                        9.41 |
| vejpt8p8 | signed        | rmse          | vejpt8p8        |                      4.26 |                        6.3 |                        5.08 |
| 06n0t40m | softplus      | rmse          | 06n0t40m        |                       7.2 |                       9.99 |                        8.82 |

We'll go forward with the percent error + rmse loss. 

Trying a few new output layers
### 
### mlp_4D_logmag_unit_tanh_exp
output layer:
``` python
def mlp_4D_logmag_unit_tanh_exp(mlp_output, state, scalar=1.0, eps=1e-8):
    """Use log-accel magnitude with exp; tanh + normalize for direction.

    The MLP predicts log(|a|); we exponentiate to ensure positivity. Direction
    logits are squashed to [-1, 1] and normalized to unit length with an epsilon
    guard. `scalar` can be used to rescale the magnitude if desired.
    """

    log_r_mag = mlp_output[0:1]
    r_mag = scalar * jnp.exp(log_r_mag)

    r_dir_logits = mlp_output[1:4]
    r_dir_bounded = jnn.tanh(r_dir_logits)
    r_dir_mag = jnp.linalg.norm(r_dir_bounded) + eps
    r_dir_unit = r_dir_bounded / r_dir_mag

    acc_pred = r_mag * r_dir_unit
    return jnp.concatenate((state[3:6], acc_pred), axis=0)
    ```
run_id: 0z7kzz6g
runtime: 1:44

| label    | wandb_source_id | complex_TBP_planar_1_test | complex_TBP_planar_10_test | complex_TBP_planar_100_test |
| :------- | :-------------- | ------------------------: | -------------------------: | --------------------------: |
| 0z7kzz6g | 0z7kzz6g        |                      4.25 |                       10.9 |                        8.46 |
the loss looks really smooth! it isn't quite converged though - let's let it run a bit longer
![[Pasted image 20251204172614.png|500]]
Let's run for 2000 steps (rather than 1000) and check in:      
run_id: y13uegx3
runtime: 3:33
![[Pasted image 20251204173227.png|500]]
looking much more converged! but generalization isn't a ton better:

| label    | wandb_source_id | complex_TBP_planar_1_test | complex_TBP_planar_10_test | complex_TBP_planar_100_test |
| :------- | :-------------- | ------------------------: | -------------------------: | --------------------------: |
| y13uegx3 | y13uegx3        |                      4.35 |                       10.4 |                        7.94 |
### mlp_4D_logmag_unit_tanh_softplus
output layer:
``` python
def mlp_4D_logmag_unit_tanh_softplus(mlp_output, state, scalar=1.0, eps=1e-8):
    """Log-accel magnitude mapped with softplus; tanh + normalize direction.

    Softplus grows more gently than exp, which can improve conditioning while
    still enforcing positivity. `scalar` optionally rescales the magnitude.
    """

    log_r_mag = mlp_output[0:1]
    r_mag = scalar * (jnn.softplus(log_r_mag) + eps)

    r_dir_logits = mlp_output[1:4]
    r_dir_bounded = jnn.tanh(r_dir_logits)
    r_dir_mag = jnp.linalg.norm(r_dir_bounded) + eps
    r_dir_unit = r_dir_bounded / r_dir_mag

    acc_pred = r_mag * r_dir_unit
    return jnp.concatenate((state[3:6], acc_pred), axis=0)
    ```
run_id: 7zmyhy53
runtime: 1:59
not converged, looking pretty similar to the previous after 1000 steps (this one in yellow):
![[Pasted image 20251204173753.png|500]]
let's try 2000 steps:
run_id: 0hchnrnl
runtime: 3:50
loss curve is essentially the exact same as the previous output (ever so slightly better but nothing notable):
![[Pasted image 20251204174526.png|500]]
![[Pasted image 20251204174610.png|500]]
None of these perform better than signed output. 

| label    | wandb_source_id | complex_TBP_planar_1_test | complex_TBP_planar_10_test | complex_TBP_planar_100_test |
| :------- | :-------------- | ------------------------: | -------------------------: | --------------------------: |
| 0hchnrnl | 0hchnrnl        |                      4.36 |                       10.4 |                        7.23 |
## mlp_4D_signed vs mlp_4D_logmag_unit_exp
mlp_4D_signed run:
run_id: rvaqd0ci
runtime: 3:56
``` python
wandb:
  group: "complex-lofi-debug"  # Change this to your desired group name

data:
  dataset_name : "complex_TBP_planar_10_train"
  problem: '2BP'

data:
  dataset_name : "complex_TBP_planar_10_train"
  problem: '2BP'

parameters:

  length_strategy:
                      [[
                        [0.0, 1.0],
                      ]]
  lr_strategy: [[0.001]]
  steps_strategy: [[2000]]
  segment_length_strategy: [[18,]]

  width: 64
  depth: 2
  train_val_split: 1.0
  batch_size: 256
  num_trajs: -1

  loss_fcn: "percent_error_plus_nmse"
  activation: leaky_relu
  feature_layer: sph_4D_rinv_vel
  output_layer: mlp_4D_signed
  planar_constraint: true

  rtol: 0.000001
  atol: 0.00000001
  ```

mlp_4D_logmag_unit_exp:
run_id: kxo5h4ht
runtime: 4:04
config is same as above with different output layer

mlp_4D_accsoftplus:
run_id: o84m56lf
runtime: 3:59

mlp_4D_unit_softplus:
run_id: p1xxwn70
runtime: 4:06

| config label                             | Acceleration output - signed (raw output) or abs val | activation function |
| :--------------------------------------- | :--------------------------------------------------- | :------------------ |
| complex-lofi-mlp_4D_signed-pe-tanh       | signed                                               | tanh                |
| complex-lofi-mlp_4D_signed-pe-leaky_relu | signed                                               | leaky relu          |
| complex-lofi-mlp_4D-pe-tanh              | abs val                                              | tanh                |
| complex-lofi-mlp_4D-pe-leaky_relu        | abs val                                              | leaky relu          |

ll

Most fun findings of the day:
**Overall, these are the best results I've gotten with training this short and segments this long**.

I've been poking around a lot particularly with output features and activation functions. I was a bit surprised yesterday to find that the "bad" output layer we had with the failure mode of acceleration direction flipping was giving the best results in terms of loss and generalization capabilities. 

No longer! **My most successful results now use an output layer in which we are actually predicting the log of acceleration rather than acceleration itself then perform the proper conversions to get predicted acceleration vector.** Reasoning: this compresses the range of acceleration magnitudes that the model must predict, taking the exponential of this log always produces a positive value of acceleration, smooth gradients. 

With a relatively stripped back training pipeline (no curriculum training of any sort, 2000 steps) we get lower acceleration errors both in training and when testing on the unseen validation datasets as compared to our conference output layer.  Like before, the table shows average acceleration error when applying the models to validation datasets.

Further details:
training orbits: 10 complex
loss: percent error + normalized rmse
activation function: leaky relu
training steps: 2000
length strat: none
segment length: 5% of total orbit (e.g. 20 segments per orbit)

| label    | Output layer                           | complex_TBP_planar_1_test | complex_TBP_planar_10_test | complex_TBP_planar_100_test |
| :------- | :------------------------------------- | ------------------------: | -------------------------: | --------------------------: |
| kxo5h4ht | mlp_4D_logmag_unit_exp (new!)          |                      4.05 |                       5.76 |                        4.65 |
| rvaqd0ci | mlp_4D_signed (conference)             |                      4.15 |                       10.7 |                        7.97 |
| o84m56lf | mlp_4D_softplus (introduced yesterday) |                       6.9 |                       9.07 |                        7.48 |
| p1xxwn70 | mlp_4D_unit_softpus                    |                      3.49 |                       8.95 |                        6.49 |
output layer details for reference:
``` python
def mlp_4D_logmag_unit_exp(mlp_output, state, scalar=1.0, eps=1e-8):
    """True log-magnitude with exp; direction normalized without tanh."""

    log_r_mag = mlp_output[0:1]
    r_mag = scalar * jnp.exp(log_r_mag)

    r_dir = mlp_output[1:4]
    r_dir_mag = jnp.linalg.norm(r_dir) + eps
    r_dir_unit = r_dir / r_dir_mag

    acc_pred = r_mag * r_dir_unit
    return jnp.concatenate((state[3:6], acc_pred), axis=0)

def mlp_4D_signed(mlp_output, state, scalar=1.0): # the "bad" one we used in the conference
    r_mag = mlp_output[0:1]
    r_dir = mlp_output[1:4]
    acc_pred = r_mag * r_dir
    return jnp.concatenate((state[3:6], acc_pred), axis=0)
    
def mlp_4D_softplus(mlp_output, state, scalar=1.0):
    r_mag = jnn.softplus(mlp_output[0:1])
    r_dir = mlp_output[1:4]
    acc_pred = r_mag * r_dir
    return jnp.concatenate((state[3:6], acc_pred), axis=0)
    
def mlp_4D_unit_softplus(mlp_output, state, scalar=1.0):
    r_mag = jnn.softplus(mlp_output[0:1])
    r_dir = mlp_output[1:4]
    r_dir_mag = jnp.linalg.norm(r_dir)
    acc_pred = r_mag * r_dir / r_dir_mag
    return jnp.concatenate((state[3:6], acc_pred), axis=0)
```

# December 3
Recap:
We are currently working on investigating the effects of having fixed the mlp output. We suspect that if we have a corrected output, we will improve generalization abilities. Yesterday, we tested if the new pipeline improved generalization ability of the model. We trained on 100 random complex orbits, and tested on a separate validation set of 100 random complex orbits. We first tested this by comparing results of training using the conference hifi config vsThe new pipeline did slightly improve generalization, and notably the lofi config was as good or better than the hifi config. I think this is mainly because lofi config switched to leaky relu. Let's see if this is true - if we change just the activation function, what happens?

TODO:
- [ ] plot datasets
- [ ] train with new and old pipeline on 1 and 10 complex orbits to compare ability to generalize
- [ ] try lofi with new and old pipeline with tanh vs leaky relu
- [ ] investigate difference in convergence times
- [ ] implement at least one visualization that John will like
- [ ] can segment length make dynamics linear? how can we test this?
- [ ] what is the effect of activation on output layers?
- [ ] how will different input/output layers affect training?
- [ ] add flag for cpu vs gpu
- [ ] figure out how to access runtime for wandb
- [ ] box and whisker plot visualization?
- [ ] brainstorm visualizations/sensitivities we want to run
- [ ] try segmentation length sweep
- [ ] implement basic latent ODE?
- [ ] after hours - clean up commit history


knobs to turn:
1. leaky_relu vs tanh
2. batch size
3. output layer and activation
## comparing lofi results
We want to see if fixing the output layer allows us to use a less handholdy training method. To test this, let's run the following tests:
1. Use the same parameters as the conference hifi config *except* do less steps and no length strategy. Use incorrect output
2. Use the same parameters as the conference hifi config *except* do less steps, no length strategy, and leaky_relu instead of tanh. Use incorrect output
3. Use the same parameters as the conference hifi config *except* do less steps and no length strategy. Use correct output
4. Use the same parameters as the conference hifi config *except* do less steps, no length strategy, and leaky_relu instead of tanh. Use correct output

### case 1
run_id: 76h805fh
runtime: 1:12
config:
``` python
wandb:
  group: "complex-lofi-mlp_4D_signed-pe-tanh"  # Change this to your desired group name

data:
  dataset_name : "complex_TBP_planar_100_train"
  problem: '2BP'

parameters:

  length_strategy:
                      [[
                        [0.0, 1.0],
                      ]]
  lr_strategy: [[0.001, ]]
  steps_strategy: [[1000, ]]
  segment_length_strategy: [[18,]]

  width: 64
  depth: 2
  train_val_split: 1.0
  batch_size: 256
  num_trajs: -1

  # loss_fcn: "mean_squared_error"
  loss_fcn: "percent_error"
  # loss_fcn: "percent_error_plus_nmse"

  activation: tanh
  # activation: leaky_relu
  # activation: elu

  feature_layer: sph_4D_rinv_vel
  # feature_layer: sph_4D_rinv_vinv
  output_layer: mlp_4D_signed
  # output_layer: mlp_4D_unit_scaled
  # output_layer: mlp_simple
  planar_constraint: true

  rtol: 0.000001
  atol: 0.00000001
  ```
### case 2
run_id: bxlii4iv
runtime: 2:26
config:
``` python
wandb:
  group: "complex-lofi-mlp_4D_signed-pe-leaky_relu"  # Change this to your desired group name

data:
  dataset_name : "complex_TBP_planar_100_train"
  problem: '2BP'

parameters:

  length_strategy:
                      [[
                        [0.0, 1.0],
                      ]]
  lr_strategy: [[0.001, ]]
  steps_strategy: [[1000, ]]
  segment_length_strategy: [[18,]]

  width: 64
  depth: 2
  train_val_split: 1.0
  batch_size: 256
  num_trajs: -1

  # loss_fcn: "mean_squared_error"
  loss_fcn: "percent_error"
  # loss_fcn: "percent_error_plus_nmse"

  # activation: tanh
  activation: leaky_relu
  # activation: elu

  feature_layer: sph_4D_rinv_vel
  # feature_layer: sph_4D_rinv_vinv
  output_layer: mlp_4D_signed
  # output_layer: mlp_4D_unit_scaled
  # output_layer: mlp_simple
  planar_constraint: true

  rtol: 0.000001
  atol: 0.00000001
  ```
why does leaky_relu take longer to train? this may just be a computer/wandb related thing/ why is my cpu usage 328%?
### case 3
run_id: rvkedxfy
runtime: 1:21
config:
``` python
wandb:
  group: "complex-lofi-mlp_4D-pe-tanh"  # Change this to your desired group name

data:
  dataset_name : "complex_TBP_planar_100_train"
  problem: '2BP'

parameters:

  length_strategy:
                      [[
                        [0.0, 1.0],
                      ]]
  lr_strategy: [[0.001, ]]
  steps_strategy: [[1000, ]]
  segment_length_strategy: [[18,]]

  width: 64
  depth: 2
  train_val_split: 1.0
  batch_size: 256
  num_trajs: -1

  # loss_fcn: "mean_squared_error"
  loss_fcn: "percent_error"
  # loss_fcn: "percent_error_plus_nmse"

  activation: tanh
  # activation: leaky_relu
  # activation: elu

  feature_layer: sph_4D_rinv_vel
  # feature_layer: sph_4D_rinv_vinv
  output_layer: mlp_4D
  # output_layer: mlp_4D_unit_scaled
  # output_layer: mlp_simple
  planar_constraint: true

  rtol: 0.000001
  atol: 0.00000001
  ```

### case 4
run_id: eb38i1t2
runtime:
config:
``` python
wandb:
  group: "complex-lofi-mlp_4D-pe-leaky_relu"  # Change this to your desired group name

data:
  dataset_name : "complex_TBP_planar_100_train"
  problem: '2BP'

parameters:

  length_strategy:
                      [[
                        [0.0, 1.0],
                      ]]
  lr_strategy: [[0.001, ]]
  steps_strategy: [[1000, ]]
  segment_length_strategy: [[18,]]

  width: 64
  depth: 2
  train_val_split: 1.0
  batch_size: 256
  num_trajs: -1

  # loss_fcn: "mean_squared_error"
  loss_fcn: "percent_error"
  # loss_fcn: "percent_error_plus_nmse"

  # activation: tanh
  activation: leaky_relu
  # activation: elu

  feature_layer: sph_4D_rinv_vel
  # feature_layer: sph_4D_rinv_vinv
  output_layer: mlp_4D
  # output_layer: mlp_4D_unit_scaled
  # output_layer: mlp_simple
  planar_constraint: true

  rtol: 0.000001
  atol: 0.00000001
  ```

What we are trying to determine here is 1. is leaky relu significantly better than tanh, 2 is abs val output significantly better than signed output and 3 are these related

Metric: acceleration eror of model applied to test dataset
Training on 100 complex orbits:

| label                                    | wandb_group_id                           | complex_TBP_planar_1_test | complex_TBP_planar_10_test | complex_TBP_planar_100_test |
| :--------------------------------------- | :--------------------------------------- | ------------------------: | -------------------------: | --------------------------: |
| complex-lofi-mlp_4D_signed-pe-tanh       | complex-lofi-mlp_4D_signed-pe-tanh       |                      11.7 |                       15.6 |                        11.8 |
| complex-lofi-mlp_4D_signed-pe-leaky_relu | complex-lofi-mlp_4D_signed-pe-leaky_relu |                      2.34 |                       2.11 |                        1.98 |
| complex-lofi-mlp_4D-pe-tanh              | complex-lofi-mlp_4D-pe-tanh              |                        19 |                       20.1 |                        16.3 |
| complex-lofi-mlp_4D-pe-leaky_relu        | complex-lofi-mlp_4D-pe-leaky_relu        |                      2.18 |                       2.72 |                        2.18 |

**Conclusions:**
- leaky_relu is sooo much better!! why is this? Let's poke at this a little bit but not dwell on it too much for now. 
- signed vs unsigned acceleration in the output layer doesn't have a major output on the overall results IN THIS CASE - the model is much more obviously improved by using leaky relu instead of tanh. I'm curious if it has an effect on convergence rate or output tracking though. Lets plot the losses and whatnot for the cases above. Also, we need to see if the results are different for when we train on fewer orbits! Let's repeat the test from yesterday for the other amounts of orbits

It doesn't look like there is a significant difference in convergence/noisiness using mlp_4D vs mlp_4D_signed

For Neural ODEs, smoothness and well-behaved derivatives often matter more than in standard nets because the ODE solver tracks the vector field continuously.

- Prefer smooth, non-saturating activations: Swish/SiLU, GELU, Softplus, ELU. They keep gradients flowing yet give a smooth vector field, which can reduce solver jitter and step count.
- ReLU/leaky ReLU work but introduce kinks; they’re usually fine, but very stiff dynamics can force smaller solver steps. If you notice step explosion or instability, try Softplus or Swish.
- Avoid hard saturation (tanh/sigmoid) unless you really need bounded dynamics; they can make the vector field flat and slow training.
- If you like leaky ReLU but want smoother negatives, PReLU (learned slope) or Softplus- shifted (e.g., softplus(x) - ln(2)) are easy swaps.
- Keep the final layer linear/identity so outputs can be negative; the hidden activation choice doesn’t prevent that.

## training on 1 complex orbit
### Abs value acceleration output
run_id: 2o6ir5kx
runtime: 0:48
config:
``` python
wandb:
  group: "complex-lofi-mlp_4D-pe-leaky_relu-1"  # Change this to your desired group name

data:
  dataset_name : "complex_TBP_planar_1_train"
  problem: '2BP'

parameters:

  length_strategy:
                      [[
                        [0.0, 1.0],
                      ]]
  lr_strategy: [[0.001, ]]
  steps_strategy: [[1000, ]]
  segment_length_strategy: [[18,]]

  width: 64
  depth: 2
  train_val_split: 1.0
  batch_size: 256
  num_trajs: -1

  # loss_fcn: "mean_squared_error"
  loss_fcn: "percent_error"
  # loss_fcn: "percent_error_plus_nmse"

  # activation: tanh
  activation: leaky_relu
  # activation: elu

  feature_layer: sph_4D_rinv_vel
  # feature_layer: sph_4D_rinv_vinv
  output_layer: mlp_4D
  # output_layer: mlp_4D_unit_scaled
  # output_layer: mlp_simple
  planar_constraint: true

  rtol: 0.000001
  atol: 0.00000001
  ```
### Signed acceleration output
run_id: zclmkvzm
runtime: 0:49
config:
``` python
wandb:
  group: "complex-lofi-mlp_4D_signed_-pe-leaky_relu-1"  # Change this to your desired group name

data:
  dataset_name : "complex_TBP_planar_1_train"
  problem: '2BP'

parameters:

  length_strategy:
                      [[
                        [0.0, 1.0],
                      ]]
  lr_strategy: [[0.001, ]]
  steps_strategy: [[1000, ]]
  segment_length_strategy: [[18,]]

  width: 64
  depth: 2
  train_val_split: 1.0
  batch_size: 256
  num_trajs: -1

  # loss_fcn: "mean_squared_error"
  loss_fcn: "percent_error"
  # loss_fcn: "percent_error_plus_nmse"

  # activation: tanh
  activation: leaky_relu
  # activation: elu

  feature_layer: sph_4D_rinv_vel
  # feature_layer: sph_4D_rinv_vinv
  output_layer: mlp_4D_signed
  # output_layer: mlp_4D_unit_scaled
  # output_layer: mlp_simple
  planar_constraint: true

  rtol: 0.000001
  atol: 0.00000001
  ```

| label                                       | wandb_group_id                              | complex_TBP_planar_1_test | complex_TBP_planar_10_test | complex_TBP_planar_100_test |
| :------------------------------------------ | :------------------------------------------ | ------------------------: | -------------------------: | --------------------------: |
| complex-lofi-mlp_4D_signed_-pe-leaky_relu-1 | complex-lofi-mlp_4D_signed_-pe-leaky_relu-1 |                       517 |                        433 |                         360 |
| complex-lofi-mlp_4D-pe-leaky_relu-1         | complex-lofi-mlp_4D-pe-leaky_relu-1         |                       459 |                        367 |                         299 |
## training on 10 complex orbits
### Abs value acceleration output
run_id: bhehtoo2
runtime: 1:54
config:
``` python
wandb:
  group: "complex-lofi-mlp_4D-pe-leaky_relu-10"  # Change this to your desired group name

data:
  dataset_name : "complex_TBP_planar_10_train"
  problem: '2BP'

parameters:

  length_strategy:
                      [[
                        [0.0, 1.0],
                      ]]
  lr_strategy: [[0.001, ]]
  steps_strategy: [[1000, ]]
  segment_length_strategy: [[18,]]

  width: 64
  depth: 2
  train_val_split: 1.0
  batch_size: 256
  num_trajs: -1

  # loss_fcn: "mean_squared_error"
  loss_fcn: "percent_error"
  # loss_fcn: "percent_error_plus_nmse"

  # activation: tanh
  activation: leaky_relu
  # activation: elu

  feature_layer: sph_4D_rinv_vel
  # feature_layer: sph_4D_rinv_vinv
  output_layer: mlp_4D
  # output_layer: mlp_4D_unit_scaled
  # output_layer: mlp_simple
  planar_constraint: true

  rtol: 0.000001
  atol: 0.00000001
  ```
![[Pasted image 20251203151828.png]]
![[Pasted image 20251203151839.png]]
![[Pasted image 20251203151844.png]]![[Pasted image 20251203151807.png]]
![[Pasted image 20251203151740.png]]
![[Pasted image 20251203151756.png]]
### Signed acceleration output
run_id: rspv9fjn
runtime: 2:10
config:
``` python
wandb:
  group: "complex-lofi-mlp_4D_signed-pe-leaky_relu-10"  # Change this to your desired group name

data:
  dataset_name : "complex_TBP_planar_10_train"
  problem: '2BP'

parameters:

  length_strategy:
                      [[
                        [0.0, 1.0],
                      ]]
  lr_strategy: [[0.001, ]]
  steps_strategy: [[1000, ]]
  segment_length_strategy: [[18,]]

  width: 64
  depth: 2
  train_val_split: 1.0
  batch_size: 256
  num_trajs: -1

  # loss_fcn: "mean_squared_error"
  loss_fcn: "percent_error"
  # loss_fcn: "percent_error_plus_nmse"

  # activation: tanh
  activation: leaky_relu
  # activation: elu

  feature_layer: sph_4D_rinv_vel
  # feature_layer: sph_4D_rinv_vinv
  output_layer: mlp_4D_signed
  # output_layer: mlp_4D_unit_scaled
  # output_layer: mlp_simple
  planar_constraint: true

  rtol: 0.000001
  atol: 0.00000001
  ```
![[Pasted image 20251203152033.png]]
![[Pasted image 20251203152039.png]]
![[Pasted image 20251203152046.png]]
![[Pasted image 20251203152054.png]]
![[Pasted image 20251203152101.png]]
![[Pasted image 20251203152116.png]]

| label                                       | wandb_group_id                              | complex_TBP_planar_1_test | complex_TBP_planar_10_test | complex_TBP_planar_100_test |
| :------------------------------------------ | :------------------------------------------ | ------------------------: | -------------------------: | --------------------------: |
| complex-lofi-mlp_4D_signed-pe-leaky_relu-10 | complex-lofi-mlp_4D_signed-pe-leaky_relu-10 |                      4.61 |                       5.93 |                        5.38 |
| complex-lofi-mlp_4D-pe-leaky_relu-10        | complex-lofi-mlp_4D-pe-leaky_relu-10        |                      14.7 |                       10.6 |                        8.16 |
- Hmm this isn't really what I expected to see? I wonder if this is because we are using a longer segment length again (length = 18/360 = 5% of orbit) - we don't see the flip flopping in this case. However, if we have a shorter segment length then the output layer may be more important. 
- Also, this is when we have a percent error loss function.
- What I am seeing based on the output feature plots is that if we predict the incorrect sign of acceleration magnitude, we *also* predict the incorrect sign of acceleration direction vector in a consistent manner that results in a_mag_signed\*a_direction being accurate. Previously, the failure mode that we were seeing was acceleration signed value and its direction randomly flipping. This could have just been when tanh was the activation? or when the segments were shorter? Or when there were less training orbits? Not sure yet. Let's investigate the output features of training on one orbit at least to see if any flipping occurs there. We are also only looking at the models applied to the training orbits. 
- Looking through results, the most common failure currently is that near periapsis, acceleration begins to point radially:
- ![[Pasted image 20251203152805.png]]
This doesn't always happen, but certainly is not uncommon. 
We also haven't completely converged - maybe if we train longer there is some point of diminishing returns?
Let's train for 5500 steps and see if this changes generalization capabilities of mlp_4D vs mlp_4D_signed

run_id ye0p3i6q (pleasant-breeze-5754)
config:
``` python
wandb:
  group: "complex-lofi-mlp_4D_signed-pe-leaky_relu-10"  # Change this to your desired group name

data:
  dataset_name : "complex_TBP_planar_10_train"
  problem: '2BP'

parameters:

  length_strategy:
                      [[[0.0,0.1],
                        [0.0, 1.0],
                      ]]
  lr_strategy: [[0.001, 0.001]]
  steps_strategy: [[500, 5000]]
  segment_length_strategy: [[18,]]

  width: 64
  depth: 2
  train_val_split: 1.0
  batch_size: 256
  num_trajs: -1

  # loss_fcn: "mean_squared_error"
  loss_fcn: "percent_error"
  # loss_fcn: "percent_error_plus_nmse"

  # activation: tanh
  activation: leaky_relu
  # activation: elu

  feature_layer: sph_4D_rinv_vel
  # feature_layer: sph_4D_rinv_vinv
  output_layer: mlp_4D_signed
  # output_layer: mlp_4D_unit_scaled
  # output_layer: mlp_simple
  planar_constraint: true

  rtol: 0.000001
  atol: 0.00000001
  ```
``
run_id ktnrm7na (avid-dragon-5753) 
config:
``` python
wandb:
  group: "complex-lofi-mlp_4D-pe-leaky_relu-10"  # Change this to your desired group name

data:
  dataset_name : "complex_TBP_planar_10_train"
  problem: '2BP'

parameters:

  length_strategy:
                      [[[0.0,0.1],
                        [0.0, 1.0],
                      ]]
  lr_strategy: [[0.001, 0.001]]
  steps_strategy: [[500, 5000]]
  segment_length_strategy: [[18,]]

  width: 64
  depth: 2
  train_val_split: 1.0
  batch_size: 256
  num_trajs: -1

  # loss_fcn: "mean_squared_error"
  loss_fcn: "percent_error"
  # loss_fcn: "percent_error_plus_nmse"

  # activation: tanh
  activation: leaky_relu
  # activation: elu

  feature_layer: sph_4D_rinv_vel
  # feature_layer: sph_4D_rinv_vinv
  output_layer: mlp_4D
  # output_layer: mlp_4D_unit_scaled
  # output_layer: mlp_simple
  planar_constraint: true

  rtol: 0.000001
  atol: 0.00000001
  ```

these spikes in the train loss are interesting
blue is mlp_4D_signed output
yellow is mlp_4D
these still don't look totally converged BUT it looks like mlp_4D converges faster
train loss is lower for mlp_4D_signed, but this doesn't speak to generalization
Let's see how these generalized
![[Pasted image 20251203154343.png]]

| label                | wandb_source_id | complex_TBP_planar_1_test | complex_TBP_planar_10_test | complex_TBP_planar_100_test |
| :------------------- | :-------------- | ------------------------: | -------------------------: | --------------------------: |
| yellow - mlp_4D      | ktnrm7na        |                      18.1 |                       12.4 |                        9.72 |
| blue - mlp_4D_signed | ye0p3i6q        |                      7.01 |                       9.41 |                        7.68 |
|                      |                 |                           |                            |                             |
Based on this, it doesn't look like the corrected output helps us. This is surprising to me. Some thoughts:
- model wasn't converged
- convergence looks to occur faster with mlp_4D vs mlp_4D_signed, but is notably noisier for mlp_4D than mlp_4D_signed
- I'm not sure if this would change when we're doing training on 3D data

I'm confused. A couple weeks ago, I found a failure model in my model. my output layer that I was previously using was mlp_4D_signed, where the output of the model consists of an acceleration value and direction, and the value could be signed. These values get multiplied together to produce an acceleration vector, which is then integrated to calculate loss. So, if the sign of the acceleration and its direction were both wrong, we could still get the correct acceleration vector. I noticed that sometimes the output features would randomly flip signs (i.e. the sign of the acceleration valu and the sign of its direction vector would both flip) but it wouldn't matter because the product of them was still the same. However, it seems like this would make learning more difficult for the model, make it harder to generalize, etc. I was expecting that if always took the absolute value of the acceleration, the direction would always be correct and the model would train and generalize better. While the direction is now properly signed, I am getting results that show a lower training loss and better generalization capabilities when I use the mlp_4D_signed output layer rather than mlp_4D (which has the absolute value of acceleration). This is surprising to me - do you know why this would be the case?

Possibilities
- Optimization landscape: forcing |acc| (mlp_4D) makes the loss non-smooth at 0 and removes the sign degree of freedom. The model now has to encode sign entirely in the direction unit vector, which can be harder early in training. With signed, the network can “spread” sign errors between magnitude and direction; gradients can point in more forgiving directions, so it converges faster and finds better minima.
- Representation flexibility: signed lets the model represent antipodal directions with a sign flip in magnitude, keeping direction vector near a stable mode. With abs, if the target direction flips (e.g., close to periapsis where acceleration direction changes rapidly), the network must swing the direction vector itself; this can be harder for a shallow/limited-width head.
- Gradient flow near zero: abs has a kink at 0; if your predicted magnitudes hover near zero early on, gradients on r_dir can be weak or noisy. The signed head gives smooth gradients through 0 (just linear), aiding learning.
- Implicit regularization: the extra symmetry in signed acts like a redundancy that can help optimization even if it doesn’t change the final physics. Enforcing a specific factorization (positive mag × unit dir) can overconstrain the model if the MLP isn’t strong enough or the data is noisy.
- Normalization/targets: if your target accelerations are noisy or have sign ambiguity (e.g., due to normalization or masking), the signed head might absorb that better.

- Even if your loss on the _acceleration vector_ is smooth (e.g., MSE between predicted and true accel), the mapping from the MLP’s raw magnitude m to the vector uses abs(m). The composite loss(abs(m) * dir(...)) has a kink where m crosses 0: the derivative w.r.t. m jumps from −∂loss/∂(acc) to +∂loss/∂(acc). That makes the overall loss non-smooth in the raw parameters.
- A kink in the loss shows up to the optimizer as a jump in the gradient direction. That can matter because:

- Gradient-based methods assume smoothness to make consistent steps; at a kink, the derivative is undefined or discontinuous, so updates can bounce or stall.
- Subgradient choices can flip sign across tiny moves (e.g., when m crosses 0), injecting noise and slowing convergence.
- Adaptive optimizers (Adam/Adagrad) treat sudden gradient changes as volatility, which can shrink steps or make them erratic.
- Second-order intuition (curvature) breaks near kinks, so momentum/step-size heuristics become less reliable.

A smooth positive map (softplus/exp) keeps gradients consistent, typically improving stability and speed, even if the true target never hits the kink.

Even when the loss is on the integrated Cartesian state, the computation graph includes abs(m) inside the ODE right-hand side. The overall mapping weights → m → abs(m) → acceleration field → integration → state → loss is a composition that inherits the non‑smooth kink at m=0. JAX will pick a subgradient there, but the derivative w.r.t. m flips sign across 0, so the loss as a function of the raw parameters is only piecewise smooth. In practice, if m doesn’t cross zero during training you won’t feel it, but when it does (early training or hard examples), the optimizer sees that discontinuity. A smooth positive map (softplus/exp) removes that kink while leaving the rest of the pipeline unchanged.

What to try:

1. Smooth the magnitude constraint: use softplus (maybe shifted) instead of hard abs so gradients don’t kink at zero.
2. Normalize the direction: if sticking with positive mag, ensure r_dir is normalized (unit) so the model isn’t juggling both mag and direction in that vector.
3. Add a small penalty for sign flips between steps if temporal consistency matters.
4. Compare width/depth or LR tuned for the constrained head; you may need a different LR when using abs.
5. Log mag and direction separately to see where the constrained head struggles (e.g., near zero crossings).

In short: the constrained factorization (positive mag + direction) changes the optimization geometry; the signed head’s extra symmetry and smooth gradients likely make training easier even if the final vector is the same.
## shorter segments
So the reason I started delving into analysis of the outputs of my mlp was originally because we were not seeing montonic trends of improvement as we increased training data and decreased segmentation length. Perhaps if we have a shorter segment length, this is when we see the flip flopping failure mode and that could be why we weren't seeing monotonic trends? Let's go back to training with segment length = 4 and see what happens when we train with lofi with mlp_4D vs mlp_4D_signed

first train with segment length = 4, acceleration is signed:
run_id: apnidf8l
runtime: 1:11
``` python
wandb:
  group: "complex-lofi-debug"  # Change this to your desired group name

data:
  dataset_name : "complex_TBP_planar_10_train"
  problem: '2BP'

parameters:

  length_strategy:
                      [[
                        [0.0, 1.0],
                      ]]
  lr_strategy: [[0.001, ]]
  steps_strategy: [[1000, ]]
  segment_length_strategy: [[4,]]

  width: 64
  depth: 2
  train_val_split: 1.0
  batch_size: 256
  num_trajs: -1

  # loss_fcn: "mean_squared_error"
  loss_fcn: "percent_error"
  # loss_fcn: "percent_error_plus_nmse"

  # activation: tanh
  activation: leaky_relu
  # activation: elu

  feature_layer: sph_4D_rinv_vel
  # feature_layer: sph_4D_rinv_vinv
  output_layer: mlp_4D_signed
  # output_layer: mlp_4D_unit_scaled
  # output_layer: mlp_simple
  planar_constraint: true

  rtol: 0.000001
  atol: 0.00000001
```

now train with segment length = 4, acceleration output is not signed:
run_id: 57mev9gj
runtime: 1:06
config: 
``` python
wandb:
  group: "complex-lofi-debug"  # Change this to your desired group name

data:
  dataset_name : "complex_TBP_planar_10_train"
  problem: '2BP'

parameters:

  length_strategy:
                      [[
                        [0.0, 1.0],
                      ]]
  lr_strategy: [[0.001, ]]
  steps_strategy: [[1000, ]]
  segment_length_strategy: [[4,]]

  width: 64
  depth: 2
  train_val_split: 1.0
  batch_size: 256
  num_trajs: -1

  # loss_fcn: "mean_squared_error"
  loss_fcn: "percent_error"
  # loss_fcn: "percent_error_plus_nmse"

  # activation: tanh
  activation: leaky_relu
  # activation: elu

  feature_layer: sph_4D_rinv_vel
  # feature_layer: sph_4D_rinv_vinv
  output_layer: mlp_4D
  # output_layer: mlp_4D_unit_scaled
  # output_layer: mlp_simple
  planar_constraint: true

  rtol: 0.000001
  atol: 0.00000001
  ```

What do we discover from this? does generalization change now?

| label         | wandb_source_id | complex_TBP_planar_1_test | complex_TBP_planar_10_test | complex_TBP_planar_100_test |
| :------------ | :-------------- | ------------------------: | -------------------------: | --------------------------: |
| mlp_4D_signed | apnidf8l        |                      4.54 |                       6.26 |                        5.76 |
| mlp_4D_abs    | 57mev9gj        |                      13.2 |                         10 |                        7.66 |
|               |                 |                           |                            |                             |
let's change abs to softplus incase we are encountering any kinks and ssee what happens:
run_id: uhm3m4dc
runtime: 1:10
config:
``` python
wandb:
  group: "complex-lofi-debug"  # Change this to your desired group name

data:
  dataset_name : "complex_TBP_planar_10_train"
  problem: '2BP'

parameters:

  length_strategy:
                      [[
                        [0.0, 1.0],
                      ]]
  lr_strategy: [[0.001, ]]
  steps_strategy: [[1000, ]]
  segment_length_strategy: [[4,]]

  width: 64
  depth: 2
  train_val_split: 1.0
  batch_size: 256
  num_trajs: -1

  # loss_fcn: "mean_squared_error"
  loss_fcn: "percent_error"
  # loss_fcn: "percent_error_plus_nmse"

  # activation: tanh
  activation: leaky_relu
  # activation: elu

  feature_layer: sph_4D_rinv_vel
  # feature_layer: sph_4D_rinv_vinv
  output_layer: mlp_4D_accsoftplus
  # output_layer: mlp_4D_unit_scaled
  # output_layer: mlp_simple
  planar_constraint: true

  rtol: 0.000001
  atol: 0.00000001
  ```

and the output layer is:
``` python
def mlp_4D_accsoftplus(mlp_output, state, scalar=1.0):
    r_mag = jnn.softplus(mlp_output[0:1])
    r_dir = mlp_output[1:4]
    acc_pred = r_mag * r_dir
    return jnp.concatenate((state[3:6], acc_pred), axis=0)
```

| label          | wandb_source_id | complex_TBP_planar_1_test | complex_TBP_planar_10_test | complex_TBP_planar_100_test |     |
| :------------- | :-------------- | ------------------------: | -------------------------: | --------------------------: | --- |
| mlp_4D_signed  | apnidf8l        |                      4.54 |                       6.26 |                        5.76 |     |
| mlp_4D_abs     | 57mev9gj        |                      13.2 |                         10 |                        7.66 |     |
| mlp_4D_sigmoid | uhm3m4dc        |                      11.8 |                         11 |                        9.63 |     |
## John Report:
Status update:
1. leaky_relu is so much better than tanh. I've been using leaky_relu for the past month+, but here's a numerical example of how much better it is. When we train on 100 complex orbits for 1000 steps, each segment = 5% of the orbit, no length strat, we get the following average acceleration errors on independent validation sets with 1, 10 and 100 orbits respectively:

| config label                             | Acceleration output - signed (raw output) or abs val | activation function | complex_TBP_planar_1_test | complex_TBP_planar_10_test | complex_TBP_planar_100_test |
| :--------------------------------------- | :--------------------------------------------------- | :------------------ | ------------------------: | -------------------------: | --------------------------: |
| complex-lofi-mlp_4D_signed-pe-tanh       | signed                                               | tanh                |                      11.7 |                       15.6 |                        11.8 |
| complex-lofi-mlp_4D_signed-pe-leaky_relu | signed                                               | leaky relu          |                      2.34 |                       2.11 |                        1.98 |
| complex-lofi-mlp_4D-pe-tanh              | abs val                                              | tanh                |                        19 |                       20.1 |                        16.3 |
| complex-lofi-mlp_4D-pe-leaky_relu        | abs val                                              | leaky relu          |                      2.18 |                       2.72 |                        2.18 |
2. Recap of what we thought would happen with different mlp output: 
   By fixing the output layer to take the acceleration's absolute value, we avoid the behavior that we sometimes saw where acceleration would go to nearly 0 because acceleration direction vector was flipping so its components were crossing 0. We hoped and hypothesized that this fix would improve training in terms of better generalization with less data, faster convergence, more accurate acceleration predictions, etc. Recall that results sent yesterday reflected training on 100 complex orbits, and I wanted to see if the "fixed" output layer would result in better generalization capabilities when training on fewer orbits. 
   
   What we're actually seeing:
   Today, I have been training on 10 random complex orbits, and testing on separate validation datasets of 1, 10, and 100 complex orbits. I was seeing that training with a signed acceleration magnitude was actually resulting in both lower training losses and better generalization than with the absolute value of the magnitude, which was not we expected. A couple thoughts on this: 
	- In the case of training on the signed acceleration output pipeline for comparison, I inspected the output features for all of the training orbits. I never see the previously observed behavior where acceleration direction and magnitude randomly flips. This doesn't mean it can't/won't happen - I want to figure out in what cases it was originally occurring. It is a failure mode that we know does sometimes exist, it's just not showing up right now.
	- I noticed the loss curves when using absolute value of acceleration were not converging smoothly and showed chaotic looking behavior. I've concludedj that abs value isn't appropriate to use since it is nondifferentiable at 0. I updated the output layer to take softplus(acc) rather than abs(acc) for more stable gradients, and this has made training much smoother. Here is an example of acceleration error in the case where our length strategy is train on 10% then 100%, segment length is 5% of total orbit, activation function is leaky relu. Yellow uses abs(acc) in the output layer, blue uses the signed acceleration, and red uses softplus(acc). Signed acceleration learns the acceleration more accurately and generalizes better, but red is much smoother. Here is the average acceleration error for each case on three validation datasets:

| training scenario | complex_TBP_planar_1_test | complex_TBP_planar_10_test | complex_TBP_planar_100_test |     |
| :---------------- | ------------------------: | -------------------------: | --------------------------: | --- |
| mlp_4D_signed     |                      4.54 |                       6.26 |                        5.76 |     |
| mlp_4D_abs        |                      13.2 |                         10 |                        7.66 |     |
| mlp_4D_sigmoid    |                      11.8 |                         11 |                        9.63 |     |
	with the following config (only changing output layer between runs):
``` python
parameters:

  length_strategy:
                      [[[0.0,0.1],
                        [0.0, 1.0],
                      ]]
  lr_strategy: [[0.001, 0.001]]
  steps_strategy: [[500, 5000]]
  segment_length_strategy: [[18,]]

  width: 64
  depth: 2
  train_val_split: 1.0
  batch_size: 256
  num_trajs: -1

  # loss_fcn: "mean_squared_error"
  loss_fcn: "percent_error"
  # loss_fcn: "percent_error_plus_nmse"

  # activation: tanh
  activation: leaky_relu
  # activation: elu

  feature_layer: sph_4D_rinv_vel
  # feature_layer: sph_4D_rinv_vinv
  output_layer: mlp_4D_accsoftplus
  # output_layer: mlp_4D_unit_scaled
  # output_layer: mlp_simple
  planar_constraint: true

  rtol: 0.000001
  atol: 0.00000001
  	```

Takeaways:
- There is more investigating to be done - I'm surprised that using the signed acceleration in the output layer results in the best model and best generalization for the given validation datasets, but I'm not convinced this is always the case since the aforementioned failure mode did not appear in these results.
- To that end, I wonder and have been testing if there are certain scenarios where the softplus(acc) is necessary. This boils down to: when do we see the flipping acceleration direction failure mode? Perhaps we more frequently see this failure mode with shorter segments, less data, certain loss functions or activation functions, certain data distributions, etc. 
- In general, acceleration error is still too high in any of these cases. I want to get this down. I showed yesterday that percent error + rmse loss helped, and I will investigate other changes further. 
## Follow up
- When we apply the model to validation orbits, should we be applying to an initial condition, propagating for one whole orbit and then calculating acceleration error based on this? Or should we be segmenting the validation orbits in some way as well?
- Why is leaky relu so much better than tanh?
- how do I prevent my hands from freezing off
- does length strat matter?
- does segmentation strat matter? will this make mlp_4D vs mlp_4D_signed matter?
- It might be useful to have a functionality where we can pull runs down, compare their configs and display to users which parameters are different
- what are the spikes in our loss when we're training for longer?
- when we train, we expect to get lower acceleration errors than what we are seeing. What improvements can we make?
	- batch size
	- output layer
	- input features
	- etc? 
- review codex answer
- Do mlp_4D_signed models struggle at periapsis in the same way that mlp_4D do?
## Notes to self:
- Make sure that if/when we put final activation back in, if we plot the output features then it should account for them going through this activation function. 

# December 2
## Datasets
### 1 simple
![[Pasted image 20251202121721.png|500]]
![[Pasted image 20251202121726.png]]

### 1 complex
![[Pasted image 20251202121714.png|500]]
![[Pasted image 20251202121738.png|1000]]
### 5 simple


### 5 complex
### 10 simple
### 10 complex
### 100 simple

### 100 complex
![[Pasted image 20251202121226.png]]
![[Pasted image 20251202121232.png]]

## Training
### complex-hifi-mlp_4D_signed
run_id: bl3987og (name different-aardvark-5734)
runtime: 4:42
config:
``` python
wandb:
  group: "complex-hifi-mlp_4D_signed"  # Change this to your desired group name

data:
  dataset_name : "complex_TBP_planar_100_train"
  problem: '2BP'

parameters:



  # EXHAUSTIVE LENGTH STRATEGY
  length_strategy:    [[
                        [0.0, 0.1],
                        [0.0, 0.2],
                        [0.0, 0.3],
                        [0.0, 0.4],
                        [0.0, 0.5],
                        [0.0, 0.6],
                        [0.0, 0.7],
                        [0.0, 0.8],
                        [0.0, 0.9],
                        [0.0, 1.0],]
                      ]

  lr_strategy: [[0.001, 0.001, 0.001,0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001]]
  steps_strategy: [[500, 500, 500, 500, 500, 500, 500, 500, 500, 500]]
  segment_length_strategy: [[18,]]


  width: 64
  depth: 2
  train_val_split: 1
  batch_size: 64
  num_trajs: -1

  # loss_fcn: "mean_squared_error"
  loss_fcn: "percent_error"

  activation: tanh
  # activation: leaky_relu
  # activation: elu

  feature_layer: sph_4D_rinv_vel
  output_layer: mlp_4D_signed
  planar_constraint: true

  rtol: 0.000001
  atol: 0.00000001
```

## complex-hifi-mlp_4D
run_id: wkifs0zj (name denim-wave-5735)
runtime: 4:42

## complex-lofi-mlp_4D
run_id: kz4x0xl0 (name rose-resonance-5763)
runtime: 1:13

## complex-lofi-mlp_4D_peplusrmse
run_id: w6uiz2b4 (name vital-mountain-5737)
runtime: 1:25
config:
``` python
wandb:
  group: "complex-lofi-mlp_4D-peplusrmse"  # Change this to your desired group name

data:
  dataset_name : "complex_TBP_planar_100_train"
  problem: '2BP'

parameters:

  length_strategy:
                      [[
                        [0.0, 1.0],
                      ]]
  lr_strategy: [[0.001, ]]
  steps_strategy: [[1000, ]]
  segment_length_strategy: [[18,]]

  width: 64
  depth: 2
  train_val_split: 1.0
  batch_size: 64
  num_trajs: -1

  # loss_fcn: "mean_squared_error"
  # loss_fcn: "percent_error"
  loss_fcn: "percent_error_plus_nmse"

  # activation: tanh
  activation: leaky_relu
  # activation: elu

  feature_layer: sph_4D_rinv_vel
  # feature_layer: sph_4D_rinv_vinv
  output_layer: mlp_4D
  # output_layer: mlp_4D_unit_scaled
  # output_layer: mlp_simple
  planar_constraint: true

  rtol: 0.000001
  atol: 0.00000001
```

| label              | wandb_group_id                 | complex_TBP_planar_1_test | complex_TBP_planar_10_test | complex_TBP_planar_100_test |     |
| :----------------- | :----------------------------- | ------------------------: | -------------------------: | --------------------------: | --- |
| HiFi MLP (pe)      | complex-hifi-mlp_4D            |                      5.49 |                       5.48 |                        4.71 |     |
| LoFi MLP (pe)      | complex-lofi-mlp_4D            |                      2.62 |                       3.28 |                        2.73 |     |
| LoFi MLP (pe+rmse) | complex-lofi-mlp_4D-peplusrmse |                      2.76 |                       2.72 |                        2.34 |     |

Metric: average acceleration error
Testing datasets in last three columns

| training config label                | Acceleration output - signed (bad) or abs val (good) | Total steps | Runtime (min:sec) | Loss                                                | complex_TBP_planar_1_test | complex_TBP_planar_10_test | complex_TBP_planar_100_test |
| :----------------------------------- | :--------------------------------------------------- | :---------- | :---------------- | :-------------------------------------------------- | ------------------------: | -------------------------: | --------------------------: |
| HiFi (conference config)             | signed                                               | 9500        | 10:02             | Percent error                                       |                      3.87 |                       3.57 |                        3.45 |
| HiFi (abs value acceleration output) | abs val                                              | 9500        | 10:21             | Percent error                                       |                      2.86 |                       3.08 |                        2.86 |
| LoFi                                 | signed                                               | 1000        | 1:08              | Percent error                                       |                      3.62 |                       3.30 |                        3.28 |
| LoFi                                 | signed                                               | 1000        | 1:15              | Percent error +  RMSE (normalized to similar scale) |                      2.56 |                       3.26 |                        3.60 |
| LoFi                                 | abs val                                              | 1000        | 1:18              | Percent error                                       |                      2.62 |                       3.28 |                        2.73 |
| LoFi                                 | abs val                                              | 1000        | 1:25              | Percent error +  RMSE (normalized to similar scale) |                      2.76 |                       2.72 |                        2.34 |



# November 26
Fixing commit history
# November 25:
- try fixing the train/val split back so that we are segmenting and then doing train/test split
- pipeline - length and segmentation strategy
- model - 
- training and testing on the same data is not good
	- perhaps we have explicit training and validation datasets
	- validation may be better
	- try different order of ops for split then segment and segment then split
- order of ops - exact same metrics, same pipeline
	- one orbit
	- we may have poor metrics
- set up code for additional metrics with validation sets
## training w longer segments
Differences:
- use percent error loss rather than percent error + rmse to make the model lighter
- segment orboits into 36 segments rather than 90
run_id: h8h0htoa
runtime: 1:09
config:
``` python
parameters:

  length_strategy:
                      [[
                        [0.0, 1.0],
                      ]]
  lr_strategy: [[0.001]]
  steps_strategy: [[2000]]
  segment_length_strategy: [[10,]]

  width: 32
  depth: 2
  train_val_split: 0.8
  batch_size: 32
  num_trajs: -1

  # loss_fcn: "mean_squared_error"
  # loss_fcn: "percent_error_with_attraction"
  loss_fcn: "percent_error"
  # loss_fcn: "percent_error_plus_nmse"

  # activation: tanh
  activation: leaky_relu
  # activation: elu

  feature_layer: sph_4D_rinv_vel
  # feature_layer: sph_4D_rinv_vinv
  # output_layer: mlp_4D_activation
  # output_layer: mlp_4D_unit_scaled
  # output_layer: mlp_simple_hybrid
  output_layer: mlp_4D
  planar_constraint: true

  rtol: 0.000001
  atol: 0.00000001
```
![[Pasted image 20251125114415.png]]
# November 21
TODO:
- [ ] cleanish commit history
- [ ] document changes
- [ ] compare convergence for model a) before any chagnes were made, b) assuring force is attractive, c) 

# November 18
Breakthrough!! We realized that the feature layer that we were using, mlp_4D (and its variants), 
## baseline
``` python
wandb:
  group: "2BP-sensitivity"  # Change this to your desired group name

data:
  dataset_name : "complex_TBP_planar_4"
  problem: '2BP'

parameters:

  length_strategy:
                      [[
                        [0.0, 1.0],
                      ]]
  lr_strategy: [[0.001]]
  steps_strategy: [[3000]]
  segment_length_strategy: [[4,]]

  width: 32
  depth: 2
  train_val_split: 0.8
  batch_size: 32
  num_trajs: -1

  # loss_fcn: "mean_squared_error"
  loss_fcn: "percent_error"
  # loss_fcn: "percent_error_plus_nmse"

  # activation: tanh
  activation: leaky_relu
  # activation: elu

  feature_layer: sph_4D_rinv_vel
  # feature_layer: sph_4D_rinv_vinv
  output_layer: mlp_4D
  # output_layer: mlp_4D_unit_scaled
  # output_layer: mlp_simple
  planar_constraint: true

  rtol: 0.000001
  atol: 0.00000001
```

run_id: z0v2rmhl
time to run: 1:29


![[Pasted image 20251118115157.png]]
![[Pasted image 20251118115124.png]]
![[Pasted image 20251118115208.png]]
![[Pasted image 20251118115228.png]]
![[Pasted image 20251118115234.png]]
![[Pasted image 20251118115254.png]]


## calculating mlp_4D using absolute value of acceleration 
# November 18
- Spent last week mostly making QoL changes to codebase, but still need to figure out what's going on with training
- We frequently see that when we change the method of training, the model will lag (or lead) the true dynamics

Debugging this behavior:
![[Pasted image 20251112102231.png]]
![[Pasted image 20251117222526.png]]
Why is acceleration magnitude differnt between the two above?

![[Pasted image 20251117222555.png]]
![[Pasted image 20251117222606.png]]
![[Pasted image 20251117222617.png]]

``` python 
self.mlp = eqx.nn.MLP(
            in_size=in_size,
            out_size=out_size,
            width_size=width,
            depth=depth,
            activation=getattr(jnn, config.parameters.activation),
            # final_activation=jnn.tanh,
            key=key,
        )
        ```

The model doesn't look converged - what if we train for longer?
## Enforcing unit vector for r
``` python
data:
  dataset_name : "complex_TBP_planar_4"
  problem: '2BP'

parameters:

  length_strategy:
                      [[
                        [0.0, 1.0],
                      ]]
  lr_strategy: [[0.001, ]]
  steps_strategy: [[1000, ]]
  segment_length_strategy: [[4,]]

  width: 16
  depth: 4
  train_val_split: 0.8
  batch_size: 32
  num_trajs: -1

  # loss_fcn: "mean_squared_error"
  loss_fcn: "percent_error"
  # loss_fcn: "percent_error_plus_nmse"

  # activation: tanh
  activation: leaky_relu
  # activation: elu

  feature_layer: sph_4D_rinv_vel
  # feature_layer: sph_4D_rinv_vinv
  # output_layer: mlp_4D
  output_layer: mlp_4D_unit_scaled
  # output_layer: mlp_simple
  planar_constraint: true

  rtol: 0.000001
  atol: 0.00000001
  ```
![[Pasted image 20251117230413.png]]
![[Pasted image 20251117230421.png]]
![[Pasted image 20251117230431.png]]
![[Pasted image 20251117230354.png]]
![[Pasted image 20251117230458.png]]
![[Pasted image 20251117230448.png]]
Thoughts/questions:
- How does activation function affect things?
- final layer activation function necessary? 
- 


















# November 11

Goal: figure out why acceleration is dipping:
![[Pasted image 20251112102231.png]]
TODO:
- [ ] verify input and output features
- [ ] speed up training with features
- [ ] fix display of input and output features - why is it only happening for one orbit?
- [ ] clean up and commit code
- [ ] fix loss curves - training steps are not currently being plotted with the correct x axis

Why do we have __call__ and solve_with_feature_capture in NeuralODE class when they do basically the same thing? 
## Baseline
config:
``` python
parameters:

  length_strategy:
                      [[ 
                        [0.0, 1.0],                        
                      ]]
  lr_strategy: [[0.001, ]]
  steps_strategy: [[1000, ]]
  segment_length_strategy: [[4,]]

  width: 16
  depth: 4
  train_val_split: 0.8
  batch_size: 32
  num_trajs: -1

  loss_fcn: "percent_error"

  activation: leaky_relu

  feature_layer: sph_4D_rinv_vel

  output_layer: mlp_4D

  planar_constraint: true

  rtol: 0.000001
  atol: 0.00000001
```
7j3cjn5u

## Activation functions:
![[Pasted image 20251112102520.png]]
# November 10

What does the output layer do?
Order of operations:
$y = [x, y, z, v_x, v_y, v_z]$ stores position and velocity. We load in our training data and normalize it, so y is already normalized before being passed into the training loop.
Then, the ODE we're learning needs $dy/dt$ which contains both $dx/dt$ (the velocities) and $dv/dt$ (the accelerations). The feature layer transforms $y$ into a compact/intelligent representation of our choice; the MLP turns that into a latent vector; the output-layer function turns that latent vector (and possibly the original stat) into a 6-vector $[\dot{x}, \dot{y}, \dot{z}, \dot{v_x}, \dot{v_y}, \dot{v_z}\}$. Diffrax integrats that to then compute losses and gradients.

**The end goal is always a 6‑dimensional dy/dt, but you don’t have to predict it all in one shot. Each output-layer helper defines a structured way to turn the MLP’s latent vector (and sometimes the current state) into that same derivative:

- mlp_simple assumes the MLP already emits a 6‑vector, so the head just returns it.
- mlp_simple_hybrid says “the first three components (dx/dt) should just be the current velocity,” so the MLP only predicts the acceleration part and we concatenate [vx, vy, vz, ax, ay, az].
- mlp_4D variants force the MLP to output an acceleration magnitude plus a direction vector, and the head reconstructs [vx, vy, vz, ax, ay, az] by combining the state’s velocities with that structured acceleration.

All of them end up with the same final derivative, but they impose different inductive biases or parameterizations on how the accelerations are produced. Choosing one head over another just changes how much structure you bake into the model before handing dy/dt to Diffrax and the losses.

**

xactly. mlp_output is just the latent vector coming out of the shared MLP—it’s the head’s job to interpret that latent into the actual state derivative. Depending on which output-layer helper you choose, that latent might encode:

- the entire 6‑vector derivative (mlp_simple),
- only the acceleration part (then the head splices in velocities from the state), or
- something more structured like [acc_magnitude, direction_vector] that the head expands back into accelerations.

So mlp_output itself isn’t the physical state; it’s whatever intermediate representation you’ve designed the head to work with before producing the final [dx/dt, dv/dt].
- Data prep happens in scripts/training/train.py: raw orbits are normalized (Normalization2BP), split, and batched. Each training batch supplies time grids ti, initial states yi[:,0,:], and masks.
    
- The model (neuralODE/neuralODE.py (lines 44-205)) is an Equinox module: a feature layer transforms each state y into a feature vector, a shared MLP maps features to an output vector, and an output-layer head (e.g., mlp_4D in neuralODE/output_layers.py (lines 12-66)) turns that vector into the 6‑dimensional state derivative. This derivative is the RHS fed to Diffrax’s diffeqsolve.
    
- Forward pass: for each trajectory in a batch, jax.vmap(model, in_axes=(0,0)) (neuralODE/losses.py (lines 6-22)) integrates the ODE across the time grid, producing predicted trajectories y_pred.
    
- Losses (neuralODE/losses.py (lines 23-209)) compare y_pred to the ground truth yi, typically via percent error or MSE variants. These losses may also add regularizers (L1/L2) or physics terms (energy drift).
    
- Backprop: Optax optimizers take loss(model, batch); JAX automatically differentiates through the Diffrax solver (Tsit5 with adjoint handled by Diffrax). Gradients flow from loss → predictions → solver states → model outputs → MLP weights/features. The optimizer updates the MLP parameters (and any scalars) each step.
    
- Metrics/visualizers: after training, helper routines capture feature-layer values, output-layer intermediates, and accelerations via solve_with_feature_capture, plot them (neuralODE/visualizers/feature_inputs.py), and log to WandB for diagnostics.

- [x] total loss, percent error, rms on the same plot
	- [ ] hope that we get tradeoff between loss functions - if not this may indicate that we are in a local minimum
	- [x] replace staircase representation in val loss with interpolated val loss
	- [x] simplify problem
	- [ ] John suspects activation function will help a lot - it looks like there is a critical radius where we go from being attracted to flying away. why do we go from attractor to repulsive force. we expect to see conical section still. 
	- [ ] accelerations should be negative in the radial direction - we could design to say a certain number must be negative. dot product between accel and position vector should be more than 90 degrees out of phase. show the direction of the acceleration vector. 

order of ops:
- [x]  simplify orbits
- change activation gelu, relu, leaky relu
- plot outputs for actual acceleration mag and direction
	- maybe new loss constraint - penalize if force isn't attractive
- expect to find a loss function that is suitable for different problems
- shouldn't really need to weight mse since everythign is already nondimensionalized

look at inputs as a function of time
John is concerned that position is constrained -1 to 1
plotting states as a function of time - true vs discrepant orbit 
input - velocity magnitude and an angle for that. or replace the velocity components completely.

QoL improvement - I want loss curves to save by default after training. This isn't happening right now . FIXED

I want to observe if acceleration is force is attractive and penalize otherwise. 
# November 7
Let's get a baseline without any learning curriculums for troubleshooting. `complex_TBP_planar_1`:
![[Pasted image 20251107160541.png|500]]
![[Pasted image 20251107160547.png|1000]]
complex_TBP_planar_4:
![[Pasted image 20251107161440.png|500]]
![[Pasted image 20251107161434.png|1000]]

## v1 - baseline
We'll start by training on complex_TBP_planar_4 to begin, with the following validation orbit:
![[Pasted image 20251107161725.png]]

The baseline config does not include any training curriculum:
``` python
data:
  dataset_name : "complex_TBP_planar_4"
  problem: '2BP'

parameters:

  ## MINIMAL LENGTH STRATEGY
  length_strategy:
                      [[ 
                        [0.0, 1.0],                        
                      ]]
  lr_strategy: [[0.001, ]]
  steps_strategy: [[1000, ]]
  segment_length_strategy: [[4,]]

  width: 16
  depth: 2
  train_val_split: 0.8
  batch_size: 32
  num_trajs: -1

  # loss_fcn: "mean_squared_error"
  loss_fcn: "percent_error"
  # loss_fcn: "percent_error_plus_nmse"

  activation: tanh
  # activation: leaky_relu
  # activation: elu

  feature_layer: sph_4D_rinv_vel
  output_layer: mlp_4D
  planar_constraint: true

  rtol: 0.000001
  atol: 0.00000001```
losses:


![[Pasted image 20251107165931.png]]

![[Pasted image 20251107170022.png]]
# November 5

Debugging heat map.

Let's recall our baseline models that we are using for comparison and building from.
currently, we are testing on `complex_TBP_planar` which has 100 orbits. This might be too much for now, so let's reduce to 1, 4, 16 orbits (this is where our original heatmap issue came from anyway)

Recall these are the datasets we are using:
![[Pasted image 20251107095101.png|500]]
![[Pasted image 20251107095245.png|1000]]

Let's start by training on the dataset with 16 orbits. 
## v1 - segmentation strategy, no length strat, percent errror loss

config:
``` python
data:
  dataset_name : "complex_TBP_planar_16"
  problem: '2BP'

parameters:

  ## MINIMAL LENGTH STRATEGY
  length_strategy:
                      [[ 
                        [0.0, 1.0],
                        [0.0, 1.0],
                        [0.0, 1.0],
                        
                      ]]
  lr_strategy: [[0.001]]
  steps_strategy: [[200, 200, 200, ]]
  segment_length_strategy: [[4, 18, 24, ]] # corresponds to 1.111%, 5%, 6.666% 

  width: 16
  depth: 2
  train_val_split: 0.8
  batch_size: 32
  num_trajs: -1


  loss_fcn: "percent_error"

  activation: tanh


  feature_layer: sph_4D_rinv_vel
  output_layer: mlp_4D
  planar_constraint: true

  rtol: 0.000001
  atol: 0.00000001
  ```
losses:
![[Pasted image 20251107102932.png]]
![[Pasted image 20251107102946.png]]

randomly selected reference orbit:
![[Pasted image 20251107104833.png]]
![[Pasted image 20251107104900.png]]

- As we increase our segment lengh, the acceleration error does initially improve but then spikes. This could indicate that the segment length in phase 3 is too long, or we have a earning rate is too high because we see that our loss and acceleration error just oscillate
- Before we declare that the length is too long, let's try lowering the learning rate for the final phase. We should probably implement a learning rate decay schedule

## v2 - segmentation strategy, no length strat, percent error loss, lower lr for final phase

Difference from previous - lower the learning rate in the last phase
``` python
data:
  dataset_name : "complex_TBP_planar_16"
  problem: '2BP'

parameters:

  ## MINIMAL LENGTH STRATEGY
  length_strategy:
                      [[ 
                        [0.0, 1.0],
                        [0.0, 1.0],
                        [0.0, 1.0],
                        
                      ]]
  lr_strategy: [[0.001, 0.001, 0.0001]]
  steps_strategy: [[200, 200, 200, ]]
  segment_length_strategy: [[4, 18, 24, ]]

  width: 16
  depth: 2
  train_val_split: 0.8
  batch_size: 32
  num_trajs: -1

  # loss_fcn: "mean_squared_error"
  loss_fcn: "percent_error"
  # loss_fcn: "percent_error_plus_nmse"

  activation: tanh
  # activation: leaky_relu
  # activation: elu

  feature_layer: sph_4D_rinv_vel
  output_layer: mlp_4D
  planar_constraint: true

  rtol: 0.000001
  atol: 0.00000001```

loss:
![[Pasted image 20251107111033.png]]
![[Pasted image 20251107111043.png]]
![[Pasted image 20251107110612.png]]

- Lowering the learning rate did help, but it looks like segment length of 24 is still too long for this case
- Let's try increasing the segment length

## v3 - segmentation strategy, no length strat, percent error loss
Difference from previous: decrease the last segment length
``` python
parameters:

  ## MINIMAL LENGTH STRATEGY
  length_strategy:
                      [[ 
                        [0.0, 1.0],
                        [0.0, 1.0],
                        [0.0, 1.0],
                        
                      ]]
  lr_strategy: [[0.001, 0.001, 0.0001]]
  steps_strategy: [[200, 200, 200, ]]
  segment_length_strategy: [[4, 18, 20, ]]

  width: 16
  depth: 2
  train_val_split: 0.8
  batch_size: 32
  num_trajs: -1

  # loss_fcn: "mean_squared_error"
  loss_fcn: "percent_error"
  # loss_fcn: "percent_error_plus_nmse"

  activation: tanh
  # activation: leaky_relu
  # activation: elu

  feature_layer: sph_4D_rinv_vel
  output_layer: mlp_4D
  planar_constraint: true

  rtol: 0.000001
  atol: 0.00000001
  ```
loss:
![[Pasted image 20251107114322.png]]
![[Pasted image 20251107114332.png]]
![[Pasted image 20251107114051.png]]
- This didn't really help but we're not converged - let's increase training steps

## v4
Difference from last - increase steps_strat for phase 1
``` python
  length_strategy:
                      [[ 
                        [0.0, 1.0],
                        [0.0, 1.0],
                        [0.0, 1.0],
                        
                      ]]
  lr_strategy: [[0.001, 0.001, 0.0001]]
  steps_strategy: [[1000, 200, 200, ]]
  segment_length_strategy: [[4, 18, 20, ]]

  width: 16
  depth: 2
  train_val_split: 0.8
  batch_size: 32
  num_trajs: -1

  # loss_fcn: "mean_squared_error"
  loss_fcn: "percent_error"
  # loss_fcn: "percent_error_plus_nmse"

  activation: tanh
  # activation: leaky_relu
  # activation: elu

  feature_layer: sph_4D_rinv_vel
  output_layer: mlp_4D
  planar_constraint: true

  rtol: 0.000001
  atol: 0.00000001
  ```

![[Pasted image 20251107121722.png]]
![[Pasted image 20251107121834.png]]
![[Pasted image 20251107115147.png]]
Interestingly, we do actually track a little better in the beginning with the longest segmentation ratio but then our errors explode. Let's try implementing a loss function that also penalizes mse.

## v5 - combined loss
Difference from last - we are using a loss combining percent error and mse. 
``` python
data:
  dataset_name : "complex_TBP_planar_16"
  problem: '2BP'

parameters:

  ## MINIMAL LENGTH STRATEGY
  length_strategy:
                      [[ 
                        [0.0, 1.0],
                        [0.0, 1.0],
                        [0.0, 1.0],
                        
                      ]]
  lr_strategy: [[0.001, 0.001, 0.0001]]
  steps_strategy: [[1000, 200, 200 ]]
  segment_length_strategy: [[4, 18, 20, ]]

  width: 16
  depth: 2
  train_val_split: 0.8
  batch_size: 32
  num_trajs: -1

  # loss_fcn: "mean_squared_error"
  # loss_fcn: "percent_error"
  loss_fcn: "percent_error_plus_nmse"

  activation: tanh
  # activation: leaky_relu
  # activation: elu

  feature_layer: sph_4D_rinv_vel
  output_layer: mlp_4D
  planar_constraint: true

  rtol: 0.000001
  atol: 0.00000001
  ```

The loss funciton now combines percent error and mse. mse is scaled so it is on a similar scale to percent error, and incliudes a weighting factor for further control:
``` python 
def percent_error_plus_nmse_loss(
    model,
    ti,
    yi,
    mask_i,
    mse_weight=1.0,
    eps=1e-8,
):
    """Blend percent error with a normalized MSE term expressed as percent."""
    y_pred = get_y_pred(model, ti, yi, mask_i)
    y_true = yi[:, 1:, :]
    y_pred = y_pred[:, 1:, :]

    threshold = 1e-8
    true_norm = jnp.linalg.norm(y_true, axis=-1)
    safe_denominator = jnp.where(true_norm < threshold, threshold, true_norm)
    mpe = jnp.linalg.norm((y_true - y_pred), axis=-1) / safe_denominator * 100
    mpe_mean = jnp.nanmean(mpe)

    mse = jnp.nanmean((y_true - y_pred) ** 2)
    ref_power = jnp.nanmean(y_true**2) + eps
    normalized_rmse = jnp.sqrt(mse / ref_power + eps) * 100.0

    return mpe_mean + mse_weight * normalized_rmse
    ```
![[Pasted image 20251107123714.png]]
![[Pasted image 20251107123725.png]]
![[Pasted image 20251107123808.png]]
![[Pasted image 20251107123245.png]]
- This is tracking a bit worse, but from comparing the magnitude of the percent error vs the actual tracked loss, the mse is contributing very little. 
- It also looks like our model may not be sufficiently complex
	- ETA: this was not true - if we change the width and depth to 32 and 3 respectiely, our acceleration error is much worse (this is in run astral-wave 5159): ![[Pasted image 20251107125020.png]]
	![[Pasted image 20251107125037.png]]
	![[Pasted image 20251107125052.png]]
Let's try weighting the mse more heavily. 
Note - the mse weight should be a parameter in the config. I'll fix this later


## v6 - combined loss w/increased weight
Difference: same as before, but mse weight = 50
![[Pasted image 20251107125856.png]]
![[Pasted image 20251107125914.png]]
![[Pasted image 20251107130500.png]]

![[Pasted image 20251107125708.png]]


TODO:
- [ ] total loss, percent error, rms on the same plot
	- [ ] hope that we get tradeoff between loss functions - if not this may indicate that we are in a local minimum
	- [ ] replace staircase representation in val loss with interpolated val loss
	- [ ] test behavior with 1 elliptic orbit
	- [ ] simplify problem
	- [ ] John suspects activation function will help a lot - it looks like there is a critical radius where we go from being attracted to flying away. why do we go from attractor to repulsive force. we expect to see conical section still. 
	- [ ] accelerations should be negative in the radial direction - we could design to say a certain number must be negative. dot product between accel and position vector should be more than 90 degrees out of phase. show the direction of the acceleration vector. 

order of ops:
- simplify orbits
- change activation gelu, relu, leaky relu
- plot outputs for actual acceleration mag and direction
	- maybe new loss constraint - penalize if force isn't attractive
- expect to find a loss function that is suitable for different problems
- shouldn't really need to weight mse since everythign is already nondimensionalized

look at inputts as a function of time
John is concerned that position is contrained -1 to 1
plotting states as a function of time - true vs discrepant orbit 
input - velocity magnitude and an angle for that. or replace the velocity components completely.















##  OLD v3 - segmentation strategy, no length strat, combined loss, mse_weight = 10 (this was usi)
``` python
data:
  dataset_name : "complex_TBP_planar_16"
  problem: '2BP'

parameters:

  ## MINIMAL LENGTH STRATEGY
  length_strategy:
                      [[ 
                        [0.0, 1.0],
                        [0.0, 1.0],
                        [0.0, 1.0],
                        
                      ]]
  lr_strategy: [[0.001]]
  steps_strategy: [[200, 200, 200, ]]
  segment_length_strategy: [[4, 18, 24, ]] # corresponds to 

  width: 16
  depth: 2
  train_val_split: 0.8
  batch_size: 32
  num_trajs: -1


  loss_fcn: "percent_error_plus_nmse"

  activation: tanh


  feature_layer: sph_4D_rinv_vel
  output_layer: mlp_4D
  planar_constraint: true

  rtol: 0.000001
  atol: 0.00000001
  ```

where the loss `percent_error_plus_nmse` is:
``` python
def percent_error_plus_nmse_loss(
    model,
    ti,
    yi,
    mask_i,
    mse_weight=10.0,
    eps=1e-8,
):
    """Blend percent error with a normalized MSE term expressed as percent."""
    y_pred = get_y_pred(model, ti, yi, mask_i)
    y_true = yi[:, 1:, :]
    y_pred = y_pred[:, 1:, :]

    threshold = 1e-8
    true_norm = jnp.linalg.norm(y_true, axis=-1)
    safe_denominator = jnp.where(true_norm < threshold, threshold, true_norm)
    mpe = jnp.linalg.norm((y_true - y_pred), axis=-1) / safe_denominator * 100
    mpe_mean = jnp.nanmean(mpe)

    mse = jnp.nanmean((y_true - y_pred) ** 2)
    ref_power = jnp.nanmean(y_true**2) + eps
    normalized_rmse = jnp.sqrt(mse / ref_power + eps) * 100.0

    return mpe_mean + mse_weight * normalized_rmse```

![[Pasted image 20251107095852.png]]
![[Pasted image 20251107095907.png]]
![[Pasted image 20251107100032.png]]



- [ ] we want to implement save best model, and ideally if we could do it by phase that would be even better
- [ ] what is a better way to test? right now we are visualizing each phase against a random validation trajectory
- [ ] add mse weight to the config
# November 5
Sick last couple days, trying to make up time.

To Do:
- [ ] better understanding of segmentation training curriculum
- [ ] 
We got the segmentation curriculum working in train.py and neuralODE.py. Transferred analogous changes to sweep.py and added some padding (but need to update to add padding for all strategies - I think I have this stashed in code or obsidian somewhere?)

On my quest to get my heat map fixed:
First, let's record changes that were made in order to plot different phases of training both for record keeping and to triple check that the behavior we are seeing in training is correct. 


testing new loss function:

# October 31
Fixing segment length strategy:
Let's move the segmenting portion of the data processing to within train_model so that we can keep the training script relatively clean. we can still load the total dataset into the main script and then 

We found that it is important to segment each training orbit into smaller segments when training our neuralODE. Otherwise, we were seeing vanishing gradients which we hypothesize is in part because the time horizon for integration is too long when we do autodiff. We now want to investigate if a training curriculum in regards to segmentation strategy would be useful, e.g. will we see improved training if we train on shorter segments then increase the lenght of these segments (though there is likely a point of diminishing returns). 

I want to be able to implement this in our scripts. We had a first pass but this put the strategy implementation within the main script, which isn't really in line with how we handle curriculum training in the case of length_strategy. Can we pass the config and original dataset to train_model, and do the segmentation within train_model based on our current phase of training or is that not the best idea? I still want to be able to log to wandb appropriately. For context, the git stash contains the previously recommended method of doing all of the dasta segmentation within the main, while I would prefer this happens within neuralODE.py l.ike the rest of our strategy work. 

Training is working as expected now in `train.py`. Let's double check `sweep.py`. Also check that metadata that is uploaded is correct now that we have a new method of training. I'll do a quick spotcheck.

I want to be able to visualize how each phase of the model training tracks an orbit. I think a good method to do this would be to load the dataset, average the orbital elements of each orbit in the dataset, and apply the model at these averaged initial conditions (but apply the model at the end of each phase of training if possible). Visualize the true orbit vs the model predicted orbit in a manner similar to Integration Visualizer at each phase, and plot acceleration statistics.
# October 29
Finishing conda-pack and unpack
# October 28
I am getting Zaratan set up so I can run large numbvers of training scripts.

Ideas for improving training:
- try new coordinates
- different loss functions
- different input and output layers
- length strategy
- segmentation curriculum learning

## Zaratan
`module load:`
- `module load <modulename>` temporarily modifies your environment so you can use specific software packages or versions without needing admin rights
	- ex. `module load python` loads python 3.10.10
- we need to use `module load` each time we start a new session unless it is automated in .bashrc
- university recommends that `module load` commands do not go in .bashrc, rather just put them in the submitted bash script

Slurm:
- `squeue --me` shows queued jobs in pending state
- `sbalance` shows account balance (I think this is shared across the lab)
- each core on Zaratan is 4GB mem
- `#SBATCH --ntasks=<n>` specifies the number of parallel tasks (processes) to launch - you would use this if running multiple instances of your program (so this would be good for me)
- `#SBATCH --cpus-per-task=<n>` is the number of cpu cores assigned to each task. Use this for multithreaded programs (like numpy) that need multiple cores per process

Getting my conda env set up:
- I have project dependencies - how do I know if these are installed on zaratan and how can I install things that are needed? I think that's the point of the conda env - I install in there in my active conda env
- I'm pretty sure that I ended up needing to pip install a few more things - how can I check curiosity to see what I have?
- am I able to change branches when I run this stuff?
-  
- can I pip install my project? I think I will have to pull the git repo into my scratch directory? do I pip install my project in my conda env?
- steps I think I will take:
	- git clone
	- pip install project ?
	- I'm also going to need to install mldsml and switch to the neuralODE-dev branch
	- is it necessary to pip install things from the pyproject.toml when it may be taken care of by just pip installing the project?
	- am I actually able to use wandb to pull datasets down from hpc? wandb on zaratan isn't communicating online but I imagine it can still pull it?
- how do I check the available memory in my scratch directory? I think I might have to store datasets on zaratan directly
- I'm going to have to pull files down from wandb. Is there a way I can pull them down and save them off locally so that we can use datasets that are already created?
- there are data transfer nodes on zaratan - how do I access them?

I am training a neuralODE. I have a git repo with many files, folders, etc. I have config.yaml files that are read in to the main training script, and these config files contain different parameters (like model size, loss function, etc). I want to run many different instances of the training script with different parameters based on these config files, so I am trying to get the code set up to run on my university's HPC. I am creating a conda environmnt to install all required dependencies. I also use another git repository central to my lab which I will have to pull down and pip install. I am looking for advice on how to get everything up and running. A few questions:
- can I pip install the repositories into the conda environment? will the dependencies also be installed?
- am I able to switch branches when I am running things on HPC? I need to be on a different branch of my lab repository
- will pip installing these projects automatically install the dependencies?

do NOT run jobs out of home directory
home directory is the only place where files are backed up - scratch and SHELL are not

```
source ~/scratch/miniforge3/etc/profile.d/conda.sh

conda activate env_name

```
# October 21

I am training neural ODEs to learn 2BP dynamics, and for simplicity I am beginning with the planar case. Through my research, I found that it is very important to each orbit in the training dataset into smaller trajectories because otherwise we see vanishing gradients (hypothesized that when we use the adjoint sensitivity method to compute the gradients, the integrand is overly stable such that when we integrate over time horizons that are too long, we get vanishing gradients). We still think length strategy is important, which refers to training on a portion of the time series of the data to warm start the model and decrease computation time, but in this plot we are just training on the entire time series. 

In this heat map, we are showing the effects of training on different numbers of randomly generated orbits and the effects of segmenting those training orbits into different numbers of segments. When we generate random training data, we set a range for each orbital element and then randomly select from there so our orbits range from LEO to GEO, circular to as eccentric as possible without intersecting the earth. The segmentation ratio indicates what percent of the total trajectory each segment makes up (e.g. 5% means that we segmented the orbit into 20 trajectories, each being 5% of the total orbit). We then test the model on datasets containing different numbers of randomly generated orbital initial conditions, apply the model to the random initial conditions, and find the percent error in the true vs model predicted acceleration averaged over all timesteps and orbits in a given test dataset.

The segmentation trends are generally as expected - the smaller the segment and shorter the time horizon for integration, the lower the error when applying the model to a test dataset. However, we don't see the expected monotonic trend that increasing number of training orbits decreases model error. 

For now, we are focusing on getting the expected smooth gradient in the bottom 3x3 (or 4x4 if necessary) grid of the heat map. Some ideas we've had:
1) to trouble shoot, try to simplify by first testing on ciruclar orbits with different sma. However, this might not be a good idea because when we learn 2BP dynamics we are basically learning the 1/r^2 term, so circular might actually be harder to learn? for context, this is our input layer:
``` python

def sph_4D_rinv_vel(y):
    pos = y[:3]
    radius = jnp.sqrt(jnp.sum(pos**2))
    return jnp.concatenate(
        [
            jnp.array(
                [
                    1 / radius,
                    pos[0] / radius,
                    pos[1] / radius,
                    pos[2] / radius,
                    *y[3:],
                ],
            ),
        ],
    )
```

and this is our output layer:
``` python
def mlp_4D(mlp_output, state, scalar=1.0):
    r_mag = mlp_output[0:1]
    r_dir = mlp_output[1:4]
    acc_pred = r_mag * r_dir
    return jnp.concatenate((state[3:6], acc_pred), axis=0)
    ```
2) should we try curriculum training with segmentation strategy? we get better results when we start with small segments, but the loss curves are quite noisy (we should also test different learning rate). maybe train first on a smaller segmentation strategy and then increase it?
3) are our input and output layers sufficient?
4) are the other parameters sufficient?
5) We currently start with a random true anomaly at the first timestep of each orbit (before segmentation) - is this necessary?
---

Let's test on a few different datasets:
**sensitivity-2D-baseline-v1:**
This tests on randomly generated orbits with the following possible ranges/params:
- SMA = \[R_Earth + 200km, R_GEO\] (where GEO is 42164 km)
- e = \[0, 0.99\] (in reality we check for intersections, so the max e is the largest eccentricity without intersecting the earth)
- planar (i = 0, RAAN and argument of periapsis undefined)
![[orbital_elements_hist_baseline 1.png]]
![[multi_dataset_xy_baseline 1.pdf]]

![[heatmap_data_sensitivity_baseline.png]]

![[W&B Chart 10_21_2025, 11_13_27 AM.png]]

![[W&B Chart 10_21_2025, 11_14_09 AM.png]]
**sensitivity-2D-fixednu0-v1**
let's generate datasets using the same random initial conditions but now nu0 = 0 for every dataset. naming scheme will be complex_TBP_planar_fixnu0_{num_orbits}

![[multi_dataset_xy_fixnu0 1.pdf]]
![[orbital_elements_hist_fixnu0.png]]
Now let us train the model
Testing on the baseline datasets with not fixed nu0:

![[heatmap_data_sensitivity_fixnu0.png]]

Testing on fixed nu0:
![[heatmap_data_sensitivity_fixnu0_testfixnu0.png]]


![[W&B Chart 10_21_2025, 11_12_54 AM.png]]
![[W&B Chart 10_21_2025, 11_12_25 AM.png]]

**sensitivity-2D-circular-v1**
This tests on circular orbits with random SMA:
![[multi_dataset_xy_circular.pdf]]

![[orbital_elements_hist_circular.png]]
Now let's train:
![[W&B Chart 10_21_2025, 11_32_15 AM.png]]

![[W&B Chart 10_21_2025, 11_32_57 AM.png]]

Testing on original datasets:
![[heatmap_data_sensitivity_circular_testbaseline.png]]
Testing on circular (training) datasets:
![[heatmap_data_sensitivity_circular.png]]























































# October 16
## Recap
We are working on 2D sensitivity analysis. Preliminary results were surprising - we were expecting to see a monotonic trend that as the number of training orbits increases, the error decreases and that as the segment ratio decreases, the error decreases. The latter is true but the former is not:
![[Pasted image 20251016122314.png]]
![[Pasted image 20251016122305.png]]
We are trying to figure out why this is happening, and want to focus on getting a nice gradient while just looking at the lower left 3x3 or 4x4 grid. 
We also noticed that the loss curves associated with this training are very noisy:
![[Pasted image 20251016122832.png]]
![[Pasted image 20251016122946.png]]
This is probably due to a variety of parameters and hyperparameters. Learning rate may be too high, segmentation strategy may put us in a local minimum that we can't get out of (maybe? double check notes from meeting), might need a training curriculum, etc. Try to get the bottom 3x3 or 4x4 of the heat map behaving expected by testing the interactions of these parameters, implementing training curriculum, etc.

## Sensitivity Analysis
Getting to the bottom of the issue described above...
The issue that we are currently investigating is that as we increase the number of training orbits, our results are not monotonically improving.

### Training data
Let's look at what our training datasets were for the first 4x4 grid:

**TBP_complex_planar_1:**
\[a, e, i, omega, w, nu\] = \[3.5359730e+04 3.7370604e-01 0.0000000e+00           nan           nan
 5.6238999e+00]\
 SMA = 35359.73 km (GEO is ~42 km)
 e = .3737
 nu0 = 322.23 deg
 ![[Pasted image 20251017124525.png|200]]
 
TBP_complex_planar_4:
![[Pasted image 20251017125450.png]]
Note to self - verify that I apply models to the test datasets
 
# October 7
## Recap
- I've begun work on 2D sensitivity studies but need to get more experiments and visualizations up and running. We need to start using the "num_trajs" parameter again for analysis.
- Finished the ASTRA poster yesterday. I made some modifications to the 2BP vector field visualization and experiment that should be documented. 
- I'm having some memory issues when I work locally, but I am having some issues with Docker and installing packages using `pip install -e .`
- I noticed that change $\nu_0$ for the test orbit after training 3D model changes the results largely, which is a bit perplexing since we also segment data. I want to investigate this. 

## Goals
- [x] Fix Docker issues
- [ ] Clean and document vis and experiment from yesterday
- [ ] 2D sensitivity studies. At a min, study num_traj vs segment_length
- [x] quick 3D study so we can talk about it in meeting
- [ ] there is one more stash from the conference I have to go through and apply/document
- [ ] prevent wandb files, artifacts, etc. from being saved locally
## Sensitivity studies
Step 1 is being able to access the parameters we want to study! For now, these include:
- [ ] number of training orbits
- [ ] segmentation strategy
- [ ] length strategy
Segmentation strategy and length strategy are already easily accessible. We also previously utilized `num_trajs` param, but this has basically been phased out in favor of training using the explicit names of datasets defined in the config. So, we can either consistently name datasets and put the num_trajs as a variable within the name (e.g. "simple_TBP_planar_5"), we can dynamically find the number of trajectories by loading the data, we can include another num_trajs param to weep over (but we would have to make sure that we have it properly corresponding to the correct dataset), or we can add a parameter to the dataset itself indicating the number of trajectories. The last option is probably our best bet since reloading data unnecessarily is expensive. 

Basically, this just means that when we train the model we should record how many orbits the model was trained on (taking into account train_test_split). We already have to load the data for training of course, so at that point we can record the number of training orbits to wandb.

I updated the training script and model save function so that we can pass optional additional arguments to log to the model. Currently, I added segment_ratio so we have direct access to the percentage each segment is of the total trajectory, as well as num_total_orbits and num_train_orbits so we don't have to do any additional data manipulation post model training.

Let's run a quick train script and make sure everything is working as expected.

Note - training is taking a very long time to run locally through docker because a lot of space isbeing used on saving artifacts, models, etc. We don't want to do this since everything is just uploaded to wandb and we can pull it down later. 



# October 6
## Recap
Working on sensitivity studies for 2D scenarios (segmentation, amount of training day, length strategy in particular)
## Goals
- [x] Finish ASTRA poster
	- [x] vector field diff plot overlaid with training orbits for a quick glance of how the training data amount impacts training
- [x] Figure out why 3D training isn't working well on test orbit (kinda done)
## 3D training
Last week, I began training on 3D orbits (as opposed to the planar ones we used for the conference). The segment length is 10, i.e. the trajectory is split into 36 segments before training. The loss curves are converging to acceptable values:
![[Pasted image 20251006110049.png]]
I did a sanity chck by testing on a random orbit that fell within the bounds of the training data and got very bad results:
![[Pasted image 20251006110119.png]]
During group meeting, Kruti asked if I had tried differ initial conditions. I had tried altering the shape of the orbit and got similarly bad results, but I had not altered the initial true anomaly.  When I change nu0 from 0 to 20 degrees, I get much better results:
![[Pasted image 20251006110526.png]]
![[Pasted image 20251006110545.png]]


What does this indicate? When we generate data, we take a random initial true anomaly from 0 to 360 degrees. The other orbital elements are randomized according to our desired dataset. When we load the data in, we segment the trajectory. Because of this segmentation, I am surprised that the initial true anomaly would have such a large impact since the model is functionally exposed to *many* different initial true anomalies through segmentation. 
This leads me to wonder: 
1) What does the full predicted vector field look like? How does this change as a function of randomizing vs not randomizing the initial true anomaly (e.g. will results be significantly different if we just always have an initial true anomaly = 0)? If we keep nu0 of the full trajectory randomized, how does the amount of training data affect the model accuracy? We would expect that increased exposure to more ICs, i.e. more training data, would improve accuracy.
2) How important is segmentation in 3D? We expect that it will have a larger effect than in 2D due to the increased dimensionality of the problem - to what extent is this true?

experiment idea for 2d: plot the residual of the vector field against the training orbits

## ASTRA Poster
I want to create the following visualization:
Train on 10 random 2D orbits (complex case). Use all orbits for training, i.e. train/val split = 1. Plot a vector field with the residual of the true versus predicted acceleration, overlayed on top of the training orbits.
- [ ] Generate training data
- [ ] Visualize
- [ ] Update yaml
- [ ] Update train script (use correct yaml)
- [ ] Train
- [ ] Visualize


