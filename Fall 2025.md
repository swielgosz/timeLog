# September 9

Recap: I am currently working on understanding how QPOs are generated for my lit review/deepening of understanding of dynamics models. To guide my understanding, I am dissecting the [CR3BP repo](https://github.com/DhruvJ22/Astrodynamics_Research) that I previously used to generate training data for my neural ODEs.

Relevant terms to learn and/or implement:
- Shooting methods
	- Single shooting methods
	- Multiple shooting methods
- Differential correction
	- STMs needed for anything involving sensitivities, corrections, or stability
- Continuation methods
- Constraints
- Crossing events

I also need to finalize a research topic for the semester. I am generally interested in looking at n-body dynamics and exploiting the latent nature of neural ODEs. What can we improve using this?

Goals for today:
- [ ]  Study and understand all the terms above at a medium level
- [ ]  Fully understand and implement shooting methods for a simple example
- [ ]  Finalize semester research topic - what are we doing that is novel? How can we exploit the latent nature of neural ODEs? What system will we study? What methods are currently used?
- [ ] Improve understanding of adjoint method - I need to know this in my sleep

## Future plans - neural ODEs for nBP
Latent space representation - a latent space is an embedding of a A latent space, also known as a latent feature space or embedding space, is an [embedding](https://en.wikipedia.org/wiki/Embedding "Embedding") of a set of items within a [manifold](https://en.wikipedia.org/wiki/Manifold "Manifold") in which items resembling each other are positioned closer to one another. Position within the latent space can be viewed as being defined by a set of [latent variables](https://en.wikipedia.org/wiki/Latent_variable "Latent variable") that emerge from the resemblances from the objects.

In most cases, the [dimensionality](https://en.wikipedia.org/wiki/Dimensionality "Dimensionality") of the latent space is chosen to be lower than the dimensionality of the [feature space](https://en.wikipedia.org/wiki/Feature_space "Feature space") from which the data points are drawn, making the construction of a latent space an example of [dimensionality reduction](https://en.wikipedia.org/wiki/Dimensionality_reduction "Dimensionality reduction"), which can also be viewed as a form of [data compression](https://en.wikipedia.org/wiki/Data_compression "Data compression").[[1]](https://en.wikipedia.org/wiki/Latent_space#cite_note-1)

Ideas:
- Encode trajectories in latent space to reveal stable/unstable manifolds for trajectory design in latent coordinates. Use to search for heteroclinic connections, design initial guesses for transfers
- Multi-fidelity residual modeling - with NBP dynamics as our baseline, let a latent ODE parameterize residuals (unmodeled forces like SRP, outgassing, drag)
- Fast surrogate propagation across regimes - encode initial pconditions to z0 svolve \dot{z}
	- Use for Monte Carlo, reachability analysis, coverage, design loops
	- Benchmark - test speedup vs high-fidelity integrator
	- Latent dynamics much simpler than raw n-body dynamics, so we get quicker propagation for Monte Carlo, optimization, design tasks
	- Use cases:
		- Trajectory Design and exploration - once trained, latent ODE can generate trajectories in milliseconds letting us sweep wide design spaces. Example - explore families of NRHOs 
		- Reachability and coverage studies cheaply
		- No: Flight computers are resource-constrained — they can’t run ephemeris-driven N-body propagation in real time.

We have a high fidelity system, we are trying to identify the eigenvalues of the system. Manifolds - emergent and converging. 

Reachability - design an envelope and propagate that envelope 
- Monte Carlo is for validating
- Reachability in the latent space on a Gaussian - propagate with neural ODE, decode with 
	- Starts Gaussian, evolves nonlinearly. Only in encoding and decoding do we go in and out 
### **High-fidelity integration**

- State dimension: 6N (for N bodies or spacecraft).
- RHS evaluation: gravitational terms + perturbations (e.g., J2, SRP, drag, ephemerides). Each RHS call can be expensive.
- Stiffness: multiple timescales → requires small timesteps.
- Runtime: seconds–minutes per trajectory (or worse for long horizons / Monte Carlo).

  

### **Neural ODE / Latent ODE integration**

- State dimension: latent vector (often **much lower** than 6N).
- RHS evaluation: a few matrix multiplies + nonlinear activations.
- Learned dynamics tend to be smoother, sometimes close to **linear/diagonal** in z-space.
- Runtime: milliseconds per trajectory.

So yes, you still integrate, but the **integration is cheap** because:
- the system is low-dimensional,
- the dynamics are simple to evaluate,
- adaptive solvers can take much larger steps.
### **Trajectory Design and Exploration**

- **Problem:** Mission designers need to explore thousands (sometimes millions) of trajectories to find feasible transfers or resonant orbits.
    
- **Latent surrogate:** Once trained, it can generate trajectories in milliseconds, letting you sweep wide design spaces.
    
- **Example:** Exploring families of NRHOs or Distant Retrograde Orbits in the Earth–Moon–Sun 4BP without re-integrating the ODEs each time.
- Control in latent coordinates where dynamics are simpler
## Shooting methods


