# January
Hurray, a new year of research! First goal (and deadline) of the year is to put out a journal paper by start of Spring semester. A list of tasks that need to be done before then
 - [ ] neuralODEs v 1.0
# January 7
Today, I need to develop an initial narrative for my journal paper and determine what is left to be done. I'm not totally sure what story I am trying to tell, because I haven't gotten to the portion of the research focusing on forced linearization of latent ODEs to find trajectories in cislunar space. It looks like the paper will focus on extending the results of the conference paper but I'm not sure if the "story" itself will develop?

 Working at my parents' house was very difficult, so I need to buckle down extra hard the next few weeks. 
To do:
- [ ] try training on 3D - compare mlp4D_unit to the other variations
- [ ] Determine what sensitivities we want to include in the journal paper
	- [ ] Plan associated visualizations - at least draw them if not actually making them
	- [ ] Plan associated tables
- [ ] Determine what CR3BP orbital families we want to include
	- [ ] Generate data
- [ ] Latent ODE work
	- [ ] Try training with MLP in GRU instead of RNN
	- [ ] Read original paper and take notes
	- [ ] Watch some of the videos that are located in Technical Notes/ Latent ODEs
- [ ] figure out when mlp4D_signed is worse (because intuitively it should be)
- [ ] CLEAN CODE
	- [ ] work on this after hours
	- [ ] a lot of stuff is repetitive and can probably can be condensed 

## Investigating output layer effects
We expect mlp_4D_signed to produce the worst outputs as discused in detail in Fall 2025 notes. It doesn't (at least for the 2D case). Thoughts:
- we need new metrics to test if physics are being obeyed. This would most likely be in the form of observig the acceleration direction - does it flip? how far does it stray from radial? etc
- It may also have more of an effect on training on 3D datasets. Let's investigate this first

### Training on 3D data
At some point we generated 3D datasets, but it was long enough ago that we should regenerate to make sure we're getting what we want. Let's use a naming convention analogous to that of our 2BP planar, which was `<complex|simple>_TBP_planar_<num_orbits>_<train|test>`. 
Let's replace "planar" with "nonplanar", and generate datasets for 1, 10, 100 orbits, simple and complex, train and test to begin with. 
Datasets to generate:
- [x] simple_TBP_nonplanar_1_train
- [x] simple_TBP_nonplanar_1_test
- [x] simple_TBP_nonplanar_10_train
- [x] simple_TBP_nonplanar_10_test
- [x] simple_TBP_nonplanar_100_train
- [x] simple_TBP_nonplanar_100_test
- [x] complex_TBP_nonplanar_1_train
- [x] complex_TBP_nonplanar_1_test
- [x] complex_TBP_nonplanar_10_train
- [x] complex_TBP_nonplanar_10_test
- [x] complex_TBP_nonplanar_100_train
- [x] complex_TBP_nonplanar_100_test

Now let's visualize the training dataset. 
![[Pasted image 20260107200043.png]]
![[Pasted image 20260107200051.png]]
Great, now let's train using mlp_4D_unit and compare to other output layers
Training progress: 100%|██████████| 3000/3000 [09:06<00:00,  5.49step/s] [repeated 25x across cluster]
sweep.py finished in 28.2 minutes (1693.9 seconds) for sweep "complex_TBP_nonplanar_10_v0"

